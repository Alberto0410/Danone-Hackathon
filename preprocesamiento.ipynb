{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing as skp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el archivo .json y las transponemos\n",
    "train = pd.read_json('data/train_products.json').T\n",
    "test = pd.read_json('data/test_products.json').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>categories_hierarchy</th>\n",
       "      <th>is_beverage</th>\n",
       "      <th>selling_countries</th>\n",
       "      <th>ingredient_origins</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>additives_count</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>...</th>\n",
       "      <th>nutrition_grade</th>\n",
       "      <th>packaging_materials</th>\n",
       "      <th>non_recyclable_and_non_biodegradable_materials_count</th>\n",
       "      <th>est_co2_agriculture</th>\n",
       "      <th>est_co2_consumption</th>\n",
       "      <th>est_co2_distribution</th>\n",
       "      <th>est_co2_packaging</th>\n",
       "      <th>est_co2_processing</th>\n",
       "      <th>est_co2_transportation</th>\n",
       "      <th>ecoscore_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pommes duchesse</td>\n",
       "      <td>Pom lisse,Pom'Lisse, Marque Repère</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[en:frozen-foods, en:frozen-fried-potatoes, en...</td>\n",
       "      <td>0</td>\n",
       "      <td>[en:france]</td>\n",
       "      <td>{'en:unknown': 100}</td>\n",
       "      <td>[{'id': 'en:potato', 'percent': 82, 'percent_e...</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>[en:plastic]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.405794</td>\n",
       "      <td>0.122097</td>\n",
       "      <td>0.151978</td>\n",
       "      <td>0.400866</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.344651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bûche pâtissière à la crème au beurre</td>\n",
       "      <td>Esprit de Fête,Carrefour</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[en:snacks, en:desserts, en:sweet-snacks, en:f...</td>\n",
       "      <td>0</td>\n",
       "      <td>[en:france]</td>\n",
       "      <td>{'en:unknown': 100}</td>\n",
       "      <td>[{'id': 'en:glucose-syrup', 'percent_estimate'...</td>\n",
       "      <td>10</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>[en:cardboard, en:plastic]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.772009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.288156</td>\n",
       "      <td>5.215055</td>\n",
       "      <td>0.171567</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cini Minis</td>\n",
       "      <td>Nestlé, Nestlé</td>\n",
       "      <td></td>\n",
       "      <td>[en:plant-based-foods-and-beverages, en:plant-...</td>\n",
       "      <td>0</td>\n",
       "      <td>[en:austria, en:france, en:germany, en:spain, ...</td>\n",
       "      <td>{'en:unknown': 100}</td>\n",
       "      <td>[{'id': 'en:whole-wheat-flour', 'percent': 37,...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.635</td>\n",
       "      <td>...</td>\n",
       "      <td>d</td>\n",
       "      <td>[en:paperboard, en:plastic]</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.281596</td>\n",
       "      <td>0.770511</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cuor di fette Carrefour</td>\n",
       "      <td>Carrefour</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[en:dairies, en:fermented-foods, en:fermented-...</td>\n",
       "      <td>0</td>\n",
       "      <td>[en:italy]</td>\n",
       "      <td>{'en:unknown': 100}</td>\n",
       "      <td>[{'has_sub_ingredients': 'yes', 'id': 'en:chee...</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>[en:plastic]</td>\n",
       "      <td>1</td>\n",
       "      <td>4.536405</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.037393</td>\n",
       "      <td>0.185784</td>\n",
       "      <td>0.458632</td>\n",
       "      <td>0.217118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Curry</td>\n",
       "      <td>Carrefour,Groupe Carrefour</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[en:plant-based-foods-and-beverages, en:plant-...</td>\n",
       "      <td>0</td>\n",
       "      <td>[en:france]</td>\n",
       "      <td>{'en:unknown': 100}</td>\n",
       "      <td>[{'id': 'en:turmeric', 'percent_estimate': 55....</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[en:glass, en:plastic, en:unknown]</td>\n",
       "      <td>0</td>\n",
       "      <td>7.918371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015709</td>\n",
       "      <td>0.47839</td>\n",
       "      <td>0.445327</td>\n",
       "      <td>0.334988</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name                               brand  \\\n",
       "0                        Pommes duchesse  Pom lisse,Pom'Lisse, Marque Repère   \n",
       "1  Bûche pâtissière à la crème au beurre            Esprit de Fête,Carrefour   \n",
       "2                             Cini Minis                      Nestlé, Nestlé   \n",
       "3                Cuor di fette Carrefour                           Carrefour   \n",
       "4                                  Curry          Carrefour,Groupe Carrefour   \n",
       "\n",
       "  generic_name                               categories_hierarchy is_beverage  \\\n",
       "0      unknown  [en:frozen-foods, en:frozen-fried-potatoes, en...           0   \n",
       "1      unknown  [en:snacks, en:desserts, en:sweet-snacks, en:f...           0   \n",
       "2               [en:plant-based-foods-and-beverages, en:plant-...           0   \n",
       "3      unknown  [en:dairies, en:fermented-foods, en:fermented-...           0   \n",
       "4      unknown  [en:plant-based-foods-and-beverages, en:plant-...           0   \n",
       "\n",
       "                                   selling_countries   ingredient_origins  \\\n",
       "0                                        [en:france]  {'en:unknown': 100}   \n",
       "1                                        [en:france]  {'en:unknown': 100}   \n",
       "2  [en:austria, en:france, en:germany, en:spain, ...  {'en:unknown': 100}   \n",
       "3                                         [en:italy]  {'en:unknown': 100}   \n",
       "4                                        [en:france]  {'en:unknown': 100}   \n",
       "\n",
       "                                         ingredients additives_count  \\\n",
       "0  [{'id': 'en:potato', 'percent': 82, 'percent_e...               1   \n",
       "1  [{'id': 'en:glucose-syrup', 'percent_estimate'...              10   \n",
       "2  [{'id': 'en:whole-wheat-flour', 'percent': 37,...               3   \n",
       "3  [{'has_sub_ingredients': 'yes', 'id': 'en:chee...               2   \n",
       "4  [{'id': 'en:turmeric', 'percent_estimate': 55....               0   \n",
       "\n",
       "  calcium_100g  ... nutrition_grade                 packaging_materials  \\\n",
       "0      unknown  ...               b                        [en:plastic]   \n",
       "1      unknown  ...               e          [en:cardboard, en:plastic]   \n",
       "2        0.635  ...               d         [en:paperboard, en:plastic]   \n",
       "3      unknown  ...               e                        [en:plastic]   \n",
       "4      unknown  ...         unknown  [en:glass, en:plastic, en:unknown]   \n",
       "\n",
       "  non_recyclable_and_non_biodegradable_materials_count est_co2_agriculture  \\\n",
       "0                                                  1              1.405794   \n",
       "1                                                  1              1.772009   \n",
       "2                                                  1                2.2396   \n",
       "3                                                  1              4.536405   \n",
       "4                                                  0              7.918371   \n",
       "\n",
       "  est_co2_consumption est_co2_distribution est_co2_packaging  \\\n",
       "0            0.122097             0.151978          0.400866   \n",
       "1                   0             0.019531          0.288156   \n",
       "2                   0             0.019531          0.281596   \n",
       "3            0.006688             0.037393          0.185784   \n",
       "4                   0             0.015709           0.47839   \n",
       "\n",
       "  est_co2_processing est_co2_transportation ecoscore_grade  \n",
       "0             0.1234               0.344651              2  \n",
       "1           5.215055               0.171567              3  \n",
       "2           0.770511               0.252874              3  \n",
       "3           0.458632               0.217118              3  \n",
       "4           0.445327               0.334988              4  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'brand', 'generic_name', 'categories_hierarchy', 'is_beverage',\n",
       "       'selling_countries', 'ingredient_origins', 'ingredients',\n",
       "       'additives_count', 'calcium_100g', 'carbohydrates_100g',\n",
       "       'energy_kcal_100g', 'fat_100g', 'fiber_100g', 'proteins_100g',\n",
       "       'salt_100g', 'sodium_100g', 'sugars_100g', 'nutrition_grade',\n",
       "       'packaging_materials',\n",
       "       'non_recyclable_and_non_biodegradable_materials_count',\n",
       "       'est_co2_agriculture', 'est_co2_consumption', 'est_co2_distribution',\n",
       "       'est_co2_packaging', 'est_co2_processing', 'est_co2_transportation',\n",
       "       'ecoscore_grade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_beverage</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>energy_kcal_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>nutrition_grade</th>\n",
       "      <th>packaging_materials</th>\n",
       "      <th>non_recyclable_and_non_biodegradable_materials_count</th>\n",
       "      <th>est_co2_agriculture</th>\n",
       "      <th>est_co2_consumption</th>\n",
       "      <th>est_co2_distribution</th>\n",
       "      <th>est_co2_packaging</th>\n",
       "      <th>est_co2_processing</th>\n",
       "      <th>est_co2_transportation</th>\n",
       "      <th>ecoscore_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.5</td>\n",
       "      <td>b</td>\n",
       "      <td>[en:plastic]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.405794</td>\n",
       "      <td>0.122097</td>\n",
       "      <td>0.151978</td>\n",
       "      <td>0.400866</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.344651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>58</td>\n",
       "      <td>366</td>\n",
       "      <td>14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>37</td>\n",
       "      <td>e</td>\n",
       "      <td>[en:cardboard, en:plastic]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.772009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.288156</td>\n",
       "      <td>5.215055</td>\n",
       "      <td>0.171567</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.635</td>\n",
       "      <td>73.8</td>\n",
       "      <td>423</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>25</td>\n",
       "      <td>d</td>\n",
       "      <td>[en:paperboard, en:plastic]</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.281596</td>\n",
       "      <td>0.770511</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>8.5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>e</td>\n",
       "      <td>[en:plastic]</td>\n",
       "      <td>1</td>\n",
       "      <td>4.536405</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.037393</td>\n",
       "      <td>0.185784</td>\n",
       "      <td>0.458632</td>\n",
       "      <td>0.217118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>[en:glass, en:plastic, en:unknown]</td>\n",
       "      <td>0</td>\n",
       "      <td>7.918371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015709</td>\n",
       "      <td>0.47839</td>\n",
       "      <td>0.445327</td>\n",
       "      <td>0.334988</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_beverage calcium_100g carbohydrates_100g energy_kcal_100g fat_100g  \\\n",
       "0           0      unknown                 21          unknown      7.1   \n",
       "1           0      unknown                 58              366       14   \n",
       "2           0        0.635               73.8              423     10.3   \n",
       "3           0      unknown                8.5          unknown       19   \n",
       "4           0      unknown                  0                0        0   \n",
       "\n",
       "  fiber_100g proteins_100g salt_100g sodium_100g sugars_100g nutrition_grade  \\\n",
       "0        2.2           2.2       0.7        0.28         0.5               b   \n",
       "1    unknown           2.9       0.3        0.12          37               e   \n",
       "2          5           6.2       0.9        0.36          25               d   \n",
       "3          0            15       2.5           1         8.5               e   \n",
       "4          0             0         0           0           0         unknown   \n",
       "\n",
       "                  packaging_materials  \\\n",
       "0                        [en:plastic]   \n",
       "1          [en:cardboard, en:plastic]   \n",
       "2         [en:paperboard, en:plastic]   \n",
       "3                        [en:plastic]   \n",
       "4  [en:glass, en:plastic, en:unknown]   \n",
       "\n",
       "  non_recyclable_and_non_biodegradable_materials_count est_co2_agriculture  \\\n",
       "0                                                  1              1.405794   \n",
       "1                                                  1              1.772009   \n",
       "2                                                  1                2.2396   \n",
       "3                                                  1              4.536405   \n",
       "4                                                  0              7.918371   \n",
       "\n",
       "  est_co2_consumption est_co2_distribution est_co2_packaging  \\\n",
       "0            0.122097             0.151978          0.400866   \n",
       "1                   0             0.019531          0.288156   \n",
       "2                   0             0.019531          0.281596   \n",
       "3            0.006688             0.037393          0.185784   \n",
       "4                   0             0.015709           0.47839   \n",
       "\n",
       "  est_co2_processing est_co2_transportation ecoscore_grade  \n",
       "0             0.1234               0.344651              2  \n",
       "1           5.215055               0.171567              3  \n",
       "2           0.770511               0.252874              3  \n",
       "3           0.458632               0.217118              3  \n",
       "4           0.445327               0.334988              4  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminamos las columnas que no tiene informacion relevante\n",
    "# respecto a la variable respuesta\n",
    "columns_drop = ['name', 'brand', 'generic_name', 'categories_hierarchy',\n",
    "                'selling_countries', 'ingredient_origins', 'ingredients',\n",
    "                'additives_count']\n",
    "\n",
    "train_drop = train.drop(columns_drop, axis=1)\n",
    "test_drop = test.drop(columns_drop, axis=1)\n",
    "\n",
    "train_drop.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a transformar la variable packaging_materials para que valga un 1 si hay plastico y 0 si no hay plastico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_beverage</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>energy_kcal_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>nutrition_grade</th>\n",
       "      <th>packaging_materials</th>\n",
       "      <th>non_recyclable_and_non_biodegradable_materials_count</th>\n",
       "      <th>est_co2_agriculture</th>\n",
       "      <th>est_co2_consumption</th>\n",
       "      <th>est_co2_distribution</th>\n",
       "      <th>est_co2_packaging</th>\n",
       "      <th>est_co2_processing</th>\n",
       "      <th>est_co2_transportation</th>\n",
       "      <th>ecoscore_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.5</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.405794</td>\n",
       "      <td>0.122097</td>\n",
       "      <td>0.151978</td>\n",
       "      <td>0.400866</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.344651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>58</td>\n",
       "      <td>366</td>\n",
       "      <td>14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>37</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.772009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.288156</td>\n",
       "      <td>5.215055</td>\n",
       "      <td>0.171567</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.635</td>\n",
       "      <td>73.8</td>\n",
       "      <td>423</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>25</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.281596</td>\n",
       "      <td>0.770511</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>8.5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.536405</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.037393</td>\n",
       "      <td>0.185784</td>\n",
       "      <td>0.458632</td>\n",
       "      <td>0.217118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.918371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015709</td>\n",
       "      <td>0.47839</td>\n",
       "      <td>0.445327</td>\n",
       "      <td>0.334988</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_beverage calcium_100g carbohydrates_100g energy_kcal_100g fat_100g  \\\n",
       "0           0      unknown                 21          unknown      7.1   \n",
       "1           0      unknown                 58              366       14   \n",
       "2           0        0.635               73.8              423     10.3   \n",
       "3           0      unknown                8.5          unknown       19   \n",
       "4           0      unknown                  0                0        0   \n",
       "\n",
       "  fiber_100g proteins_100g salt_100g sodium_100g sugars_100g nutrition_grade  \\\n",
       "0        2.2           2.2       0.7        0.28         0.5               b   \n",
       "1    unknown           2.9       0.3        0.12          37               e   \n",
       "2          5           6.2       0.9        0.36          25               d   \n",
       "3          0            15       2.5           1         8.5               e   \n",
       "4          0             0         0           0           0         unknown   \n",
       "\n",
       "   packaging_materials non_recyclable_and_non_biodegradable_materials_count  \\\n",
       "0                    1                                                  1     \n",
       "1                    0                                                  1     \n",
       "2                    0                                                  1     \n",
       "3                    1                                                  1     \n",
       "4                    0                                                  0     \n",
       "\n",
       "  est_co2_agriculture est_co2_consumption est_co2_distribution  \\\n",
       "0            1.405794            0.122097             0.151978   \n",
       "1            1.772009                   0             0.019531   \n",
       "2              2.2396                   0             0.019531   \n",
       "3            4.536405            0.006688             0.037393   \n",
       "4            7.918371                   0             0.015709   \n",
       "\n",
       "  est_co2_packaging est_co2_processing est_co2_transportation ecoscore_grade  \n",
       "0          0.400866             0.1234               0.344651              2  \n",
       "1          0.288156           5.215055               0.171567              3  \n",
       "2          0.281596           0.770511               0.252874              3  \n",
       "3          0.185784           0.458632               0.217118              3  \n",
       "4           0.47839           0.445327               0.334988              4  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transforma la variable packaging_material en una variable dummy\n",
    "def contains_plastic(list_material):\n",
    "    '''Función que '''\n",
    "    if 'plastic' in list_material[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "train_drop['packaging_materials'] = train_drop['packaging_materials'].apply(contains_plastic)\n",
    "test_drop['packaging_materials'] = test_drop['packaging_materials'].apply(contains_plastic)\n",
    "train_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a los producto que no tienen informacion de nutriton_grade se les asigna una c\n",
    "train_drop['nutrition_grade'] = train_drop['nutrition_grade'].apply(lambda x: 'c' if x == 'unknown' else x)\n",
    "test_drop['nutrition_grade'] = test_drop['nutrition_grade'].apply(lambda x: 'c' if x == 'unknown' else x)\n",
    "\n",
    "#eliminamos la variable calcium_100g por tener muchos valores nulos\n",
    "train_drop = train_drop.drop('calcium_100g', axis=1)\n",
    "test_drop = test_drop.drop('calcium_100g', axis=1)\n",
    "\n",
    "def imputar_mean(df, variable):\n",
    "    '''Función que imputa la media de una variable a los valores nulos'''\n",
    "    #primero reemplazamos los valores unknown por np.nan\n",
    "    df[variable] = df[variable].apply(lambda x: np.nan if x == 'unknown' else x).astype(float)\n",
    "    mean = df[variable].mean()\n",
    "    df[variable] = df[variable].fillna(mean)\n",
    "\n",
    "imputar_mean(train_drop, 'carbohydrates_100g')\n",
    "imputar_mean(train_drop, 'energy_kcal_100g')\n",
    "imputar_mean(train_drop, 'fat_100g')\n",
    "imputar_mean(train_drop, 'fiber_100g')\n",
    "imputar_mean(train_drop, 'proteins_100g')\n",
    "imputar_mean(train_drop, 'salt_100g')\n",
    "imputar_mean(train_drop, 'sodium_100g')\n",
    "imputar_mean(train_drop, 'sugars_100g')\n",
    "\n",
    "imputar_mean(test_drop, 'carbohydrates_100g')\n",
    "imputar_mean(test_drop, 'energy_kcal_100g')\n",
    "imputar_mean(test_drop, 'fat_100g')\n",
    "imputar_mean(test_drop, 'fiber_100g')\n",
    "imputar_mean(test_drop, 'proteins_100g')\n",
    "imputar_mean(test_drop, 'salt_100g')\n",
    "imputar_mean(test_drop, 'sodium_100g')\n",
    "imputar_mean(test_drop, 'sugars_100g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_beverage</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>energy_kcal_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>nutrition_grade</th>\n",
       "      <th>packaging_materials</th>\n",
       "      <th>non_recyclable_and_non_biodegradable_materials_count</th>\n",
       "      <th>est_co2_agriculture</th>\n",
       "      <th>est_co2_consumption</th>\n",
       "      <th>est_co2_distribution</th>\n",
       "      <th>est_co2_packaging</th>\n",
       "      <th>est_co2_processing</th>\n",
       "      <th>est_co2_transportation</th>\n",
       "      <th>ecoscore_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>270.01574</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.5</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.405794</td>\n",
       "      <td>0.122097</td>\n",
       "      <td>0.151978</td>\n",
       "      <td>0.400866</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.344651</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>366.00000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.809586</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>37.0</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.772009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.288156</td>\n",
       "      <td>5.215055</td>\n",
       "      <td>0.171567</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>73.8</td>\n",
       "      <td>423.00000</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>25.0</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2396</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.281596</td>\n",
       "      <td>0.770511</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>270.01574</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.5</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.536405</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.037393</td>\n",
       "      <td>0.185784</td>\n",
       "      <td>0.458632</td>\n",
       "      <td>0.217118</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.918371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015709</td>\n",
       "      <td>0.47839</td>\n",
       "      <td>0.445327</td>\n",
       "      <td>0.334988</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_beverage  carbohydrates_100g  energy_kcal_100g  fat_100g  fiber_100g  \\\n",
       "0           0                21.0         270.01574       7.1    2.200000   \n",
       "1           0                58.0         366.00000      14.0    2.809586   \n",
       "2           0                73.8         423.00000      10.3    5.000000   \n",
       "3           0                 8.5         270.01574      19.0    0.000000   \n",
       "4           0                 0.0           0.00000       0.0    0.000000   \n",
       "\n",
       "   proteins_100g  salt_100g  sodium_100g  sugars_100g nutrition_grade  \\\n",
       "0            2.2        0.7         0.28          0.5               b   \n",
       "1            2.9        0.3         0.12         37.0               e   \n",
       "2            6.2        0.9         0.36         25.0               d   \n",
       "3           15.0        2.5         1.00          8.5               e   \n",
       "4            0.0        0.0         0.00          0.0               c   \n",
       "\n",
       "   packaging_materials non_recyclable_and_non_biodegradable_materials_count  \\\n",
       "0                    1                                                  1     \n",
       "1                    0                                                  1     \n",
       "2                    0                                                  1     \n",
       "3                    1                                                  1     \n",
       "4                    0                                                  0     \n",
       "\n",
       "  est_co2_agriculture est_co2_consumption est_co2_distribution  \\\n",
       "0            1.405794            0.122097             0.151978   \n",
       "1            1.772009                   0             0.019531   \n",
       "2              2.2396                   0             0.019531   \n",
       "3            4.536405            0.006688             0.037393   \n",
       "4            7.918371                   0             0.015709   \n",
       "\n",
       "  est_co2_packaging est_co2_processing est_co2_transportation ecoscore_grade  \n",
       "0          0.400866             0.1234               0.344651              2  \n",
       "1          0.288156           5.215055               0.171567              3  \n",
       "2          0.281596           0.770511               0.252874              3  \n",
       "3          0.185784           0.458632               0.217118              3  \n",
       "4           0.47839           0.445327               0.334988              4  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalmente pasamos la variable nutrition_grade a numerica\n",
    "train_drop['nutrition_grade'] = train_drop['nutrition_grade'].apply(lambda x: ord(x) - 97)\n",
    "test_drop['nutrition_grade'] = test_drop['nutrition_grade'].apply(lambda x: ord(x) - 97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos entre variables explicativas y variable respuesta\n",
    "X = train_drop.drop('nutrition_grade', axis=1)\n",
    "y = train_drop['nutrition_grade']\n",
    "\n",
    "#separamos en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 2001, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos una red con tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasamos a tensores\n",
    "X_train_tensor = tf.convert_to_tensor(X_train.values, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test.values, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train.values, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test.values, dtype=tf.float32)\n",
    "\n",
    "#noramlizamos los datos\n",
    "X_train_tensor = tf.keras.utils.normalize(X_train_tensor, axis=1)\n",
    "X_test_tensor = tf.keras.utils.normalize(X_test_tensor, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_121 (Dense)           (None, 1024)              19456     \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,242,373\n",
      "Trainable params: 1,242,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creamos el modelo y agragamos dropout\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1024, activation='relu', input_shape=[len(X_train.keys())]),\n",
    "    # keras.layers.Dropout(0.1),\n",
    "    # keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    # keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    # keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    # keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "#visualizamos el modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2591 - accuracy: 0.9035 - val_loss: 0.9012 - val_accuracy: 0.7955\n",
      "Epoch 2/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2575 - accuracy: 0.9053 - val_loss: 0.8973 - val_accuracy: 0.7943\n",
      "Epoch 3/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2592 - accuracy: 0.9016 - val_loss: 0.8958 - val_accuracy: 0.7924\n",
      "Epoch 4/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2588 - accuracy: 0.9009 - val_loss: 0.8971 - val_accuracy: 0.7941\n",
      "Epoch 5/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2586 - accuracy: 0.9011 - val_loss: 0.9179 - val_accuracy: 0.7943\n",
      "Epoch 6/600\n",
      "261/261 [==============================] - 4s 16ms/step - loss: 0.2577 - accuracy: 0.9027 - val_loss: 0.9068 - val_accuracy: 0.7967\n",
      "Epoch 7/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2588 - accuracy: 0.9026 - val_loss: 0.9070 - val_accuracy: 0.7910\n",
      "Epoch 8/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2596 - accuracy: 0.9025 - val_loss: 0.9029 - val_accuracy: 0.7955\n",
      "Epoch 9/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2565 - accuracy: 0.9056 - val_loss: 0.8986 - val_accuracy: 0.7922\n",
      "Epoch 10/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2570 - accuracy: 0.9049 - val_loss: 0.9017 - val_accuracy: 0.7900\n",
      "Epoch 11/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2562 - accuracy: 0.9044 - val_loss: 0.8977 - val_accuracy: 0.7948\n",
      "Epoch 12/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2558 - accuracy: 0.9028 - val_loss: 0.9103 - val_accuracy: 0.7931\n",
      "Epoch 13/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2581 - accuracy: 0.9026 - val_loss: 0.9074 - val_accuracy: 0.7907\n",
      "Epoch 14/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2552 - accuracy: 0.9042 - val_loss: 0.9087 - val_accuracy: 0.7936\n",
      "Epoch 15/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2565 - accuracy: 0.9030 - val_loss: 0.9016 - val_accuracy: 0.7963\n",
      "Epoch 16/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2548 - accuracy: 0.9050 - val_loss: 0.9056 - val_accuracy: 0.7960\n",
      "Epoch 17/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2561 - accuracy: 0.9038 - val_loss: 0.9128 - val_accuracy: 0.7941\n",
      "Epoch 18/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2545 - accuracy: 0.9044 - val_loss: 0.9045 - val_accuracy: 0.7934\n",
      "Epoch 19/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2559 - accuracy: 0.9038 - val_loss: 0.9150 - val_accuracy: 0.7946\n",
      "Epoch 20/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2532 - accuracy: 0.9062 - val_loss: 0.9095 - val_accuracy: 0.7922\n",
      "Epoch 21/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2539 - accuracy: 0.9065 - val_loss: 0.9187 - val_accuracy: 0.7888\n",
      "Epoch 22/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2542 - accuracy: 0.9046 - val_loss: 0.9093 - val_accuracy: 0.7929\n",
      "Epoch 23/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2547 - accuracy: 0.9056 - val_loss: 0.9193 - val_accuracy: 0.7907\n",
      "Epoch 24/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2537 - accuracy: 0.9045 - val_loss: 0.9213 - val_accuracy: 0.7931\n",
      "Epoch 25/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2522 - accuracy: 0.9049 - val_loss: 0.9204 - val_accuracy: 0.7891\n",
      "Epoch 26/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2529 - accuracy: 0.9053 - val_loss: 0.9306 - val_accuracy: 0.7898\n",
      "Epoch 27/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2521 - accuracy: 0.9050 - val_loss: 0.9192 - val_accuracy: 0.7946\n",
      "Epoch 28/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2521 - accuracy: 0.9053 - val_loss: 0.9176 - val_accuracy: 0.7864\n",
      "Epoch 29/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2553 - accuracy: 0.9036 - val_loss: 0.9168 - val_accuracy: 0.7910\n",
      "Epoch 30/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2529 - accuracy: 0.9062 - val_loss: 0.9276 - val_accuracy: 0.7936\n",
      "Epoch 31/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2518 - accuracy: 0.9060 - val_loss: 0.9185 - val_accuracy: 0.7924\n",
      "Epoch 32/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2499 - accuracy: 0.9067 - val_loss: 0.9318 - val_accuracy: 0.7864\n",
      "Epoch 33/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2519 - accuracy: 0.9041 - val_loss: 0.9270 - val_accuracy: 0.7869\n",
      "Epoch 34/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2500 - accuracy: 0.9069 - val_loss: 0.9311 - val_accuracy: 0.7919\n",
      "Epoch 35/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2521 - accuracy: 0.9045 - val_loss: 0.9253 - val_accuracy: 0.7929\n",
      "Epoch 36/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2492 - accuracy: 0.9065 - val_loss: 0.9236 - val_accuracy: 0.7931\n",
      "Epoch 37/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2504 - accuracy: 0.9054 - val_loss: 0.9230 - val_accuracy: 0.7967\n",
      "Epoch 38/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2496 - accuracy: 0.9083 - val_loss: 0.9203 - val_accuracy: 0.7941\n",
      "Epoch 39/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2508 - accuracy: 0.9048 - val_loss: 0.9255 - val_accuracy: 0.7917\n",
      "Epoch 40/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2493 - accuracy: 0.9048 - val_loss: 0.9301 - val_accuracy: 0.7934\n",
      "Epoch 41/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2501 - accuracy: 0.9046 - val_loss: 0.9280 - val_accuracy: 0.7989\n",
      "Epoch 42/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2507 - accuracy: 0.9060 - val_loss: 0.9215 - val_accuracy: 0.7960\n",
      "Epoch 43/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2472 - accuracy: 0.9048 - val_loss: 0.9285 - val_accuracy: 0.7948\n",
      "Epoch 44/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2494 - accuracy: 0.9053 - val_loss: 0.9326 - val_accuracy: 0.7939\n",
      "Epoch 45/600\n",
      "261/261 [==============================] - 4s 16ms/step - loss: 0.2481 - accuracy: 0.9078 - val_loss: 0.9326 - val_accuracy: 0.7965\n",
      "Epoch 46/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2470 - accuracy: 0.9068 - val_loss: 0.9303 - val_accuracy: 0.7915\n",
      "Epoch 47/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2482 - accuracy: 0.9069 - val_loss: 0.9365 - val_accuracy: 0.7895\n",
      "Epoch 48/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2479 - accuracy: 0.9081 - val_loss: 0.9297 - val_accuracy: 0.7931\n",
      "Epoch 49/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2475 - accuracy: 0.9068 - val_loss: 0.9434 - val_accuracy: 0.7965\n",
      "Epoch 50/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2480 - accuracy: 0.9090 - val_loss: 0.9407 - val_accuracy: 0.7960\n",
      "Epoch 51/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2461 - accuracy: 0.9089 - val_loss: 0.9289 - val_accuracy: 0.7979\n",
      "Epoch 52/600\n",
      "261/261 [==============================] - 4s 16ms/step - loss: 0.2456 - accuracy: 0.9087 - val_loss: 0.9319 - val_accuracy: 0.7941\n",
      "Epoch 53/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2466 - accuracy: 0.9078 - val_loss: 0.9449 - val_accuracy: 0.7943\n",
      "Epoch 54/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2445 - accuracy: 0.9090 - val_loss: 0.9440 - val_accuracy: 0.7905\n",
      "Epoch 55/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2457 - accuracy: 0.9088 - val_loss: 0.9470 - val_accuracy: 0.7941\n",
      "Epoch 56/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2441 - accuracy: 0.9093 - val_loss: 0.9402 - val_accuracy: 0.7955\n",
      "Epoch 57/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2462 - accuracy: 0.9068 - val_loss: 0.9446 - val_accuracy: 0.7965\n",
      "Epoch 58/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2446 - accuracy: 0.9078 - val_loss: 0.9496 - val_accuracy: 0.7924\n",
      "Epoch 59/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2449 - accuracy: 0.9081 - val_loss: 0.9421 - val_accuracy: 0.7948\n",
      "Epoch 60/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2435 - accuracy: 0.9105 - val_loss: 0.9653 - val_accuracy: 0.7857\n",
      "Epoch 61/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2441 - accuracy: 0.9088 - val_loss: 0.9402 - val_accuracy: 0.7960\n",
      "Epoch 62/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2439 - accuracy: 0.9087 - val_loss: 0.9522 - val_accuracy: 0.7972\n",
      "Epoch 63/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2421 - accuracy: 0.9095 - val_loss: 0.9672 - val_accuracy: 0.7879\n",
      "Epoch 64/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2446 - accuracy: 0.9080 - val_loss: 0.9475 - val_accuracy: 0.7931\n",
      "Epoch 65/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2430 - accuracy: 0.9079 - val_loss: 0.9501 - val_accuracy: 0.7934\n",
      "Epoch 66/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2424 - accuracy: 0.9087 - val_loss: 0.9638 - val_accuracy: 0.7915\n",
      "Epoch 67/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2415 - accuracy: 0.9107 - val_loss: 0.9587 - val_accuracy: 0.7927\n",
      "Epoch 68/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2421 - accuracy: 0.9093 - val_loss: 0.9600 - val_accuracy: 0.7919\n",
      "Epoch 69/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2445 - accuracy: 0.9072 - val_loss: 0.9596 - val_accuracy: 0.7888\n",
      "Epoch 70/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2435 - accuracy: 0.9079 - val_loss: 0.9646 - val_accuracy: 0.7917\n",
      "Epoch 71/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2394 - accuracy: 0.9093 - val_loss: 0.9564 - val_accuracy: 0.7941\n",
      "Epoch 72/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2423 - accuracy: 0.9079 - val_loss: 0.9764 - val_accuracy: 0.7919\n",
      "Epoch 73/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2403 - accuracy: 0.9111 - val_loss: 0.9710 - val_accuracy: 0.7903\n",
      "Epoch 74/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2402 - accuracy: 0.9104 - val_loss: 0.9706 - val_accuracy: 0.7946\n",
      "Epoch 75/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2430 - accuracy: 0.9101 - val_loss: 0.9625 - val_accuracy: 0.7958\n",
      "Epoch 76/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2438 - accuracy: 0.9096 - val_loss: 0.9589 - val_accuracy: 0.7943\n",
      "Epoch 77/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2382 - accuracy: 0.9108 - val_loss: 0.9604 - val_accuracy: 0.7919\n",
      "Epoch 78/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2395 - accuracy: 0.9099 - val_loss: 0.9623 - val_accuracy: 0.7931\n",
      "Epoch 79/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2385 - accuracy: 0.9088 - val_loss: 0.9612 - val_accuracy: 0.7891\n",
      "Epoch 80/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2378 - accuracy: 0.9119 - val_loss: 0.9970 - val_accuracy: 0.7761\n",
      "Epoch 81/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2414 - accuracy: 0.9099 - val_loss: 0.9621 - val_accuracy: 0.7941\n",
      "Epoch 82/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2398 - accuracy: 0.9119 - val_loss: 0.9628 - val_accuracy: 0.7960\n",
      "Epoch 83/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2378 - accuracy: 0.9122 - val_loss: 0.9787 - val_accuracy: 0.7893\n",
      "Epoch 84/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2395 - accuracy: 0.9098 - val_loss: 0.9679 - val_accuracy: 0.7941\n",
      "Epoch 85/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2375 - accuracy: 0.9113 - val_loss: 0.9745 - val_accuracy: 0.7905\n",
      "Epoch 86/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2366 - accuracy: 0.9123 - val_loss: 0.9746 - val_accuracy: 0.7943\n",
      "Epoch 87/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2365 - accuracy: 0.9128 - val_loss: 0.9800 - val_accuracy: 0.7929\n",
      "Epoch 88/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2388 - accuracy: 0.9110 - val_loss: 0.9738 - val_accuracy: 0.7900\n",
      "Epoch 89/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2386 - accuracy: 0.9117 - val_loss: 0.9736 - val_accuracy: 0.7955\n",
      "Epoch 90/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2359 - accuracy: 0.9132 - val_loss: 0.9702 - val_accuracy: 0.7915\n",
      "Epoch 91/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2376 - accuracy: 0.9096 - val_loss: 0.9797 - val_accuracy: 0.7948\n",
      "Epoch 92/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2369 - accuracy: 0.9118 - val_loss: 0.9826 - val_accuracy: 0.7946\n",
      "Epoch 93/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2373 - accuracy: 0.9121 - val_loss: 0.9802 - val_accuracy: 0.7941\n",
      "Epoch 94/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2378 - accuracy: 0.9111 - val_loss: 0.9925 - val_accuracy: 0.7967\n",
      "Epoch 95/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2353 - accuracy: 0.9134 - val_loss: 0.9809 - val_accuracy: 0.7970\n",
      "Epoch 96/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2338 - accuracy: 0.9150 - val_loss: 0.9812 - val_accuracy: 0.7943\n",
      "Epoch 97/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2359 - accuracy: 0.9113 - val_loss: 0.9872 - val_accuracy: 0.7955\n",
      "Epoch 98/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2342 - accuracy: 0.9142 - val_loss: 0.9853 - val_accuracy: 0.7934\n",
      "Epoch 99/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2339 - accuracy: 0.9137 - val_loss: 0.9871 - val_accuracy: 0.7922\n",
      "Epoch 100/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2371 - accuracy: 0.9131 - val_loss: 0.9877 - val_accuracy: 0.7907\n",
      "Epoch 101/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2328 - accuracy: 0.9154 - val_loss: 0.9876 - val_accuracy: 0.7984\n",
      "Epoch 102/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2339 - accuracy: 0.9125 - val_loss: 1.0039 - val_accuracy: 0.7843\n",
      "Epoch 103/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2338 - accuracy: 0.9145 - val_loss: 0.9807 - val_accuracy: 0.7967\n",
      "Epoch 104/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2347 - accuracy: 0.9117 - val_loss: 0.9870 - val_accuracy: 0.7939\n",
      "Epoch 105/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2329 - accuracy: 0.9144 - val_loss: 0.9868 - val_accuracy: 0.7960\n",
      "Epoch 106/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2336 - accuracy: 0.9132 - val_loss: 0.9835 - val_accuracy: 0.7958\n",
      "Epoch 107/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2351 - accuracy: 0.9115 - val_loss: 0.9851 - val_accuracy: 0.7939\n",
      "Epoch 108/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2326 - accuracy: 0.9120 - val_loss: 0.9885 - val_accuracy: 0.7991\n",
      "Epoch 109/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2312 - accuracy: 0.9161 - val_loss: 0.9859 - val_accuracy: 0.7934\n",
      "Epoch 110/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2330 - accuracy: 0.9143 - val_loss: 0.9895 - val_accuracy: 0.7965\n",
      "Epoch 111/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2302 - accuracy: 0.9143 - val_loss: 1.0063 - val_accuracy: 0.7965\n",
      "Epoch 112/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2324 - accuracy: 0.9103 - val_loss: 0.9874 - val_accuracy: 0.7939\n",
      "Epoch 113/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2317 - accuracy: 0.9129 - val_loss: 0.9975 - val_accuracy: 0.7963\n",
      "Epoch 114/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2314 - accuracy: 0.9135 - val_loss: 0.9867 - val_accuracy: 0.7960\n",
      "Epoch 115/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2308 - accuracy: 0.9138 - val_loss: 0.9930 - val_accuracy: 0.7960\n",
      "Epoch 116/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2304 - accuracy: 0.9135 - val_loss: 1.0062 - val_accuracy: 0.7943\n",
      "Epoch 117/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2326 - accuracy: 0.9140 - val_loss: 1.0031 - val_accuracy: 0.7931\n",
      "Epoch 118/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2309 - accuracy: 0.9149 - val_loss: 0.9954 - val_accuracy: 0.7960\n",
      "Epoch 119/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2316 - accuracy: 0.9125 - val_loss: 0.9984 - val_accuracy: 0.7939\n",
      "Epoch 120/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2289 - accuracy: 0.9170 - val_loss: 0.9942 - val_accuracy: 0.7965\n",
      "Epoch 121/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2288 - accuracy: 0.9150 - val_loss: 1.0045 - val_accuracy: 0.7917\n",
      "Epoch 122/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2295 - accuracy: 0.9159 - val_loss: 1.0035 - val_accuracy: 0.7903\n",
      "Epoch 123/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2289 - accuracy: 0.9139 - val_loss: 1.0097 - val_accuracy: 0.7931\n",
      "Epoch 124/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2297 - accuracy: 0.9149 - val_loss: 0.9981 - val_accuracy: 0.7946\n",
      "Epoch 125/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2311 - accuracy: 0.9136 - val_loss: 0.9974 - val_accuracy: 0.7975\n",
      "Epoch 126/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2294 - accuracy: 0.9152 - val_loss: 1.0276 - val_accuracy: 0.7828\n",
      "Epoch 127/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2297 - accuracy: 0.9145 - val_loss: 1.0099 - val_accuracy: 0.7936\n",
      "Epoch 128/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2284 - accuracy: 0.9158 - val_loss: 1.0096 - val_accuracy: 0.7891\n",
      "Epoch 129/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2274 - accuracy: 0.9140 - val_loss: 1.0097 - val_accuracy: 0.7965\n",
      "Epoch 130/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2273 - accuracy: 0.9178 - val_loss: 1.0176 - val_accuracy: 0.7900\n",
      "Epoch 131/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2280 - accuracy: 0.9164 - val_loss: 1.0099 - val_accuracy: 0.7963\n",
      "Epoch 132/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2267 - accuracy: 0.9163 - val_loss: 1.0140 - val_accuracy: 0.7919\n",
      "Epoch 133/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2282 - accuracy: 0.9152 - val_loss: 1.0101 - val_accuracy: 0.7924\n",
      "Epoch 134/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2262 - accuracy: 0.9174 - val_loss: 1.0041 - val_accuracy: 0.7987\n",
      "Epoch 135/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2283 - accuracy: 0.9160 - val_loss: 1.0144 - val_accuracy: 0.7943\n",
      "Epoch 136/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2264 - accuracy: 0.9144 - val_loss: 1.0133 - val_accuracy: 0.7929\n",
      "Epoch 137/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2244 - accuracy: 0.9188 - val_loss: 1.0299 - val_accuracy: 0.7939\n",
      "Epoch 138/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2287 - accuracy: 0.9151 - val_loss: 1.0164 - val_accuracy: 0.7967\n",
      "Epoch 139/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2271 - accuracy: 0.9143 - val_loss: 1.0272 - val_accuracy: 0.7907\n",
      "Epoch 140/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2236 - accuracy: 0.9168 - val_loss: 1.0139 - val_accuracy: 0.7948\n",
      "Epoch 141/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2248 - accuracy: 0.9157 - val_loss: 1.0217 - val_accuracy: 0.7967\n",
      "Epoch 142/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2244 - accuracy: 0.9173 - val_loss: 1.0150 - val_accuracy: 0.7917\n",
      "Epoch 143/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2240 - accuracy: 0.9186 - val_loss: 1.0215 - val_accuracy: 0.7919\n",
      "Epoch 144/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2257 - accuracy: 0.9171 - val_loss: 1.0193 - val_accuracy: 0.7958\n",
      "Epoch 145/600\n",
      "261/261 [==============================] - 3s 13ms/step - loss: 0.2256 - accuracy: 0.9149 - val_loss: 1.0291 - val_accuracy: 0.7955\n",
      "Epoch 146/600\n",
      "261/261 [==============================] - 3s 13ms/step - loss: 0.2251 - accuracy: 0.9163 - val_loss: 1.0193 - val_accuracy: 0.7967\n",
      "Epoch 147/600\n",
      "261/261 [==============================] - 3s 13ms/step - loss: 0.2218 - accuracy: 0.9176 - val_loss: 1.0237 - val_accuracy: 0.7970\n",
      "Epoch 148/600\n",
      "261/261 [==============================] - 3s 13ms/step - loss: 0.2220 - accuracy: 0.9185 - val_loss: 1.0299 - val_accuracy: 0.7934\n",
      "Epoch 149/600\n",
      "261/261 [==============================] - 3s 13ms/step - loss: 0.2226 - accuracy: 0.9184 - val_loss: 1.0315 - val_accuracy: 0.7948\n",
      "Epoch 150/600\n",
      "261/261 [==============================] - 3s 13ms/step - loss: 0.2254 - accuracy: 0.9178 - val_loss: 1.0298 - val_accuracy: 0.7975\n",
      "Epoch 151/600\n",
      "261/261 [==============================] - 3s 13ms/step - loss: 0.2223 - accuracy: 0.9173 - val_loss: 1.0271 - val_accuracy: 0.7948\n",
      "Epoch 152/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2248 - accuracy: 0.9173 - val_loss: 1.0266 - val_accuracy: 0.7972\n",
      "Epoch 153/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2207 - accuracy: 0.9179 - val_loss: 1.0318 - val_accuracy: 0.7934\n",
      "Epoch 154/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2209 - accuracy: 0.9177 - val_loss: 1.0385 - val_accuracy: 0.7948\n",
      "Epoch 155/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2210 - accuracy: 0.9201 - val_loss: 1.0406 - val_accuracy: 0.7907\n",
      "Epoch 156/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2220 - accuracy: 0.9174 - val_loss: 1.0469 - val_accuracy: 0.7905\n",
      "Epoch 157/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2238 - accuracy: 0.9176 - val_loss: 1.0340 - val_accuracy: 0.7948\n",
      "Epoch 158/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2203 - accuracy: 0.9194 - val_loss: 1.0383 - val_accuracy: 0.7970\n",
      "Epoch 159/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2205 - accuracy: 0.9180 - val_loss: 1.0335 - val_accuracy: 0.7936\n",
      "Epoch 160/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2192 - accuracy: 0.9198 - val_loss: 1.0421 - val_accuracy: 0.7967\n",
      "Epoch 161/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2212 - accuracy: 0.9181 - val_loss: 1.0338 - val_accuracy: 0.7982\n",
      "Epoch 162/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2205 - accuracy: 0.9167 - val_loss: 1.0491 - val_accuracy: 0.7927\n",
      "Epoch 163/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2224 - accuracy: 0.9173 - val_loss: 1.0398 - val_accuracy: 0.7946\n",
      "Epoch 164/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2206 - accuracy: 0.9185 - val_loss: 1.0294 - val_accuracy: 0.7963\n",
      "Epoch 165/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2205 - accuracy: 0.9176 - val_loss: 1.0445 - val_accuracy: 0.7948\n",
      "Epoch 166/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2208 - accuracy: 0.9201 - val_loss: 1.0423 - val_accuracy: 0.7958\n",
      "Epoch 167/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2190 - accuracy: 0.9192 - val_loss: 1.0701 - val_accuracy: 0.7881\n",
      "Epoch 168/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2201 - accuracy: 0.9177 - val_loss: 1.0620 - val_accuracy: 0.7927\n",
      "Epoch 169/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2182 - accuracy: 0.9185 - val_loss: 1.0488 - val_accuracy: 0.7951\n",
      "Epoch 170/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2191 - accuracy: 0.9175 - val_loss: 1.0600 - val_accuracy: 0.7934\n",
      "Epoch 171/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2193 - accuracy: 0.9181 - val_loss: 1.0454 - val_accuracy: 0.7987\n",
      "Epoch 172/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2179 - accuracy: 0.9190 - val_loss: 1.0504 - val_accuracy: 0.7922\n",
      "Epoch 173/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2187 - accuracy: 0.9176 - val_loss: 1.0503 - val_accuracy: 0.7927\n",
      "Epoch 174/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2186 - accuracy: 0.9202 - val_loss: 1.0600 - val_accuracy: 0.7912\n",
      "Epoch 175/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2197 - accuracy: 0.9184 - val_loss: 1.0443 - val_accuracy: 0.7991\n",
      "Epoch 176/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2180 - accuracy: 0.9176 - val_loss: 1.0590 - val_accuracy: 0.7948\n",
      "Epoch 177/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2181 - accuracy: 0.9189 - val_loss: 1.0565 - val_accuracy: 0.7907\n",
      "Epoch 178/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2160 - accuracy: 0.9217 - val_loss: 1.0591 - val_accuracy: 0.7941\n",
      "Epoch 179/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2157 - accuracy: 0.9189 - val_loss: 1.0578 - val_accuracy: 0.7936\n",
      "Epoch 180/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2156 - accuracy: 0.9205 - val_loss: 1.0637 - val_accuracy: 0.7927\n",
      "Epoch 181/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2154 - accuracy: 0.9202 - val_loss: 1.0653 - val_accuracy: 0.7960\n",
      "Epoch 182/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2182 - accuracy: 0.9203 - val_loss: 1.0623 - val_accuracy: 0.7939\n",
      "Epoch 183/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2144 - accuracy: 0.9192 - val_loss: 1.0585 - val_accuracy: 0.7972\n",
      "Epoch 184/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2167 - accuracy: 0.9203 - val_loss: 1.0510 - val_accuracy: 0.7953\n",
      "Epoch 185/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2144 - accuracy: 0.9222 - val_loss: 1.0593 - val_accuracy: 0.7979\n",
      "Epoch 186/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2159 - accuracy: 0.9200 - val_loss: 1.0687 - val_accuracy: 0.7972\n",
      "Epoch 187/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2145 - accuracy: 0.9207 - val_loss: 1.0684 - val_accuracy: 0.7958\n",
      "Epoch 188/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2147 - accuracy: 0.9208 - val_loss: 1.0701 - val_accuracy: 0.7955\n",
      "Epoch 189/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2131 - accuracy: 0.9229 - val_loss: 1.0739 - val_accuracy: 0.7943\n",
      "Epoch 190/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2136 - accuracy: 0.9213 - val_loss: 1.0642 - val_accuracy: 0.7967\n",
      "Epoch 191/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2140 - accuracy: 0.9201 - val_loss: 1.0673 - val_accuracy: 0.7987\n",
      "Epoch 192/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2148 - accuracy: 0.9222 - val_loss: 1.0777 - val_accuracy: 0.7975\n",
      "Epoch 193/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2128 - accuracy: 0.9225 - val_loss: 1.0725 - val_accuracy: 0.8013\n",
      "Epoch 194/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2176 - accuracy: 0.9206 - val_loss: 1.0719 - val_accuracy: 0.7965\n",
      "Epoch 195/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2138 - accuracy: 0.9208 - val_loss: 1.0656 - val_accuracy: 0.7910\n",
      "Epoch 196/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2122 - accuracy: 0.9215 - val_loss: 1.0652 - val_accuracy: 0.7965\n",
      "Epoch 197/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2113 - accuracy: 0.9210 - val_loss: 1.0726 - val_accuracy: 0.7970\n",
      "Epoch 198/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2144 - accuracy: 0.9222 - val_loss: 1.0843 - val_accuracy: 0.7883\n",
      "Epoch 199/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2119 - accuracy: 0.9200 - val_loss: 1.0765 - val_accuracy: 0.7979\n",
      "Epoch 200/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2125 - accuracy: 0.9208 - val_loss: 1.0786 - val_accuracy: 0.7963\n",
      "Epoch 201/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2116 - accuracy: 0.9218 - val_loss: 1.0755 - val_accuracy: 0.7965\n",
      "Epoch 202/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2161 - accuracy: 0.9209 - val_loss: 1.0883 - val_accuracy: 0.7982\n",
      "Epoch 203/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2140 - accuracy: 0.9207 - val_loss: 1.0745 - val_accuracy: 0.7960\n",
      "Epoch 204/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2094 - accuracy: 0.9234 - val_loss: 1.0899 - val_accuracy: 0.7948\n",
      "Epoch 205/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2093 - accuracy: 0.9245 - val_loss: 1.0776 - val_accuracy: 0.7934\n",
      "Epoch 206/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2093 - accuracy: 0.9238 - val_loss: 1.0830 - val_accuracy: 0.7931\n",
      "Epoch 207/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2091 - accuracy: 0.9237 - val_loss: 1.0750 - val_accuracy: 0.7955\n",
      "Epoch 208/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2111 - accuracy: 0.9228 - val_loss: 1.0812 - val_accuracy: 0.7919\n",
      "Epoch 209/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2103 - accuracy: 0.9234 - val_loss: 1.1028 - val_accuracy: 0.7919\n",
      "Epoch 210/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2109 - accuracy: 0.9212 - val_loss: 1.0785 - val_accuracy: 0.7975\n",
      "Epoch 211/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2102 - accuracy: 0.9209 - val_loss: 1.0814 - val_accuracy: 0.7979\n",
      "Epoch 212/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2089 - accuracy: 0.9239 - val_loss: 1.0860 - val_accuracy: 0.7989\n",
      "Epoch 213/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2090 - accuracy: 0.9240 - val_loss: 1.0944 - val_accuracy: 0.7987\n",
      "Epoch 214/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2107 - accuracy: 0.9222 - val_loss: 1.0893 - val_accuracy: 0.7941\n",
      "Epoch 215/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2092 - accuracy: 0.9237 - val_loss: 1.0921 - val_accuracy: 0.7967\n",
      "Epoch 216/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2073 - accuracy: 0.9234 - val_loss: 1.0932 - val_accuracy: 0.7975\n",
      "Epoch 217/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2073 - accuracy: 0.9246 - val_loss: 1.0967 - val_accuracy: 0.7982\n",
      "Epoch 218/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2068 - accuracy: 0.9248 - val_loss: 1.0994 - val_accuracy: 0.7946\n",
      "Epoch 219/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2100 - accuracy: 0.9220 - val_loss: 1.1042 - val_accuracy: 0.7917\n",
      "Epoch 220/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2069 - accuracy: 0.9238 - val_loss: 1.1080 - val_accuracy: 0.7939\n",
      "Epoch 221/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2079 - accuracy: 0.9249 - val_loss: 1.1031 - val_accuracy: 0.7948\n",
      "Epoch 222/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2069 - accuracy: 0.9247 - val_loss: 1.0909 - val_accuracy: 0.7951\n",
      "Epoch 223/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2097 - accuracy: 0.9215 - val_loss: 1.1010 - val_accuracy: 0.8011\n",
      "Epoch 224/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2083 - accuracy: 0.9240 - val_loss: 1.1048 - val_accuracy: 0.7970\n",
      "Epoch 225/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2071 - accuracy: 0.9245 - val_loss: 1.1090 - val_accuracy: 0.7960\n",
      "Epoch 226/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2078 - accuracy: 0.9237 - val_loss: 1.1166 - val_accuracy: 0.7934\n",
      "Epoch 227/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2051 - accuracy: 0.9237 - val_loss: 1.1034 - val_accuracy: 0.7946\n",
      "Epoch 228/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2066 - accuracy: 0.9249 - val_loss: 1.1020 - val_accuracy: 0.7965\n",
      "Epoch 229/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2061 - accuracy: 0.9242 - val_loss: 1.1107 - val_accuracy: 0.7888\n",
      "Epoch 230/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2073 - accuracy: 0.9235 - val_loss: 1.1085 - val_accuracy: 0.7963\n",
      "Epoch 231/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2084 - accuracy: 0.9225 - val_loss: 1.1110 - val_accuracy: 0.7965\n",
      "Epoch 232/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2053 - accuracy: 0.9242 - val_loss: 1.1099 - val_accuracy: 0.7958\n",
      "Epoch 233/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2064 - accuracy: 0.9231 - val_loss: 1.1129 - val_accuracy: 0.7941\n",
      "Epoch 234/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2044 - accuracy: 0.9230 - val_loss: 1.1053 - val_accuracy: 0.7979\n",
      "Epoch 235/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2051 - accuracy: 0.9235 - val_loss: 1.1114 - val_accuracy: 0.7970\n",
      "Epoch 236/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2043 - accuracy: 0.9250 - val_loss: 1.1121 - val_accuracy: 0.7967\n",
      "Epoch 237/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2060 - accuracy: 0.9231 - val_loss: 1.1137 - val_accuracy: 0.7934\n",
      "Epoch 238/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2054 - accuracy: 0.9245 - val_loss: 1.1040 - val_accuracy: 0.7967\n",
      "Epoch 239/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2020 - accuracy: 0.9262 - val_loss: 1.1154 - val_accuracy: 0.7963\n",
      "Epoch 240/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2042 - accuracy: 0.9241 - val_loss: 1.1357 - val_accuracy: 0.7934\n",
      "Epoch 241/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2038 - accuracy: 0.9218 - val_loss: 1.1314 - val_accuracy: 0.7948\n",
      "Epoch 242/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2055 - accuracy: 0.9248 - val_loss: 1.1256 - val_accuracy: 0.7943\n",
      "Epoch 243/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2046 - accuracy: 0.9248 - val_loss: 1.1279 - val_accuracy: 0.7941\n",
      "Epoch 244/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2021 - accuracy: 0.9251 - val_loss: 1.1387 - val_accuracy: 0.7936\n",
      "Epoch 245/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2011 - accuracy: 0.9266 - val_loss: 1.1377 - val_accuracy: 0.7881\n",
      "Epoch 246/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2028 - accuracy: 0.9245 - val_loss: 1.1322 - val_accuracy: 0.7931\n",
      "Epoch 247/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2046 - accuracy: 0.9249 - val_loss: 1.1254 - val_accuracy: 0.7979\n",
      "Epoch 248/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2012 - accuracy: 0.9248 - val_loss: 1.1314 - val_accuracy: 0.7970\n",
      "Epoch 249/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2017 - accuracy: 0.9249 - val_loss: 1.1459 - val_accuracy: 0.7922\n",
      "Epoch 250/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2032 - accuracy: 0.9242 - val_loss: 1.1384 - val_accuracy: 0.7939\n",
      "Epoch 251/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2036 - accuracy: 0.9239 - val_loss: 1.1274 - val_accuracy: 0.7912\n",
      "Epoch 252/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2017 - accuracy: 0.9261 - val_loss: 1.1296 - val_accuracy: 0.7965\n",
      "Epoch 253/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2008 - accuracy: 0.9259 - val_loss: 1.1327 - val_accuracy: 0.7970\n",
      "Epoch 254/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2014 - accuracy: 0.9270 - val_loss: 1.1329 - val_accuracy: 0.7931\n",
      "Epoch 255/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2025 - accuracy: 0.9259 - val_loss: 1.1248 - val_accuracy: 0.7924\n",
      "Epoch 256/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2003 - accuracy: 0.9251 - val_loss: 1.1332 - val_accuracy: 0.7912\n",
      "Epoch 257/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2012 - accuracy: 0.9261 - val_loss: 1.1486 - val_accuracy: 0.7989\n",
      "Epoch 258/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1995 - accuracy: 0.9255 - val_loss: 1.1370 - val_accuracy: 0.7929\n",
      "Epoch 259/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2010 - accuracy: 0.9258 - val_loss: 1.1395 - val_accuracy: 0.7955\n",
      "Epoch 260/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.2050 - accuracy: 0.9246 - val_loss: 1.1371 - val_accuracy: 0.7970\n",
      "Epoch 261/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1976 - accuracy: 0.9278 - val_loss: 1.1358 - val_accuracy: 0.7970\n",
      "Epoch 262/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2009 - accuracy: 0.9256 - val_loss: 1.1503 - val_accuracy: 0.7951\n",
      "Epoch 263/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2000 - accuracy: 0.9255 - val_loss: 1.1378 - val_accuracy: 0.7898\n",
      "Epoch 264/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1992 - accuracy: 0.9257 - val_loss: 1.1549 - val_accuracy: 0.7905\n",
      "Epoch 265/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.2003 - accuracy: 0.9266 - val_loss: 1.1404 - val_accuracy: 0.7943\n",
      "Epoch 266/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1997 - accuracy: 0.9263 - val_loss: 1.1489 - val_accuracy: 0.7963\n",
      "Epoch 267/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1970 - accuracy: 0.9280 - val_loss: 1.1468 - val_accuracy: 0.7965\n",
      "Epoch 268/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1988 - accuracy: 0.9266 - val_loss: 1.1512 - val_accuracy: 0.7939\n",
      "Epoch 269/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1983 - accuracy: 0.9261 - val_loss: 1.1794 - val_accuracy: 0.7907\n",
      "Epoch 270/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1999 - accuracy: 0.9278 - val_loss: 1.1577 - val_accuracy: 0.7900\n",
      "Epoch 271/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1971 - accuracy: 0.9270 - val_loss: 1.1462 - val_accuracy: 0.7960\n",
      "Epoch 272/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1980 - accuracy: 0.9275 - val_loss: 1.1715 - val_accuracy: 0.7900\n",
      "Epoch 273/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1955 - accuracy: 0.9282 - val_loss: 1.1532 - val_accuracy: 0.7958\n",
      "Epoch 274/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1955 - accuracy: 0.9288 - val_loss: 1.1483 - val_accuracy: 0.7972\n",
      "Epoch 275/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1965 - accuracy: 0.9283 - val_loss: 1.1854 - val_accuracy: 0.7867\n",
      "Epoch 276/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1953 - accuracy: 0.9288 - val_loss: 1.1555 - val_accuracy: 0.7955\n",
      "Epoch 277/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1966 - accuracy: 0.9274 - val_loss: 1.1646 - val_accuracy: 0.7946\n",
      "Epoch 278/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1966 - accuracy: 0.9276 - val_loss: 1.1630 - val_accuracy: 0.7948\n",
      "Epoch 279/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1958 - accuracy: 0.9287 - val_loss: 1.1564 - val_accuracy: 0.7967\n",
      "Epoch 280/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1939 - accuracy: 0.9288 - val_loss: 1.1627 - val_accuracy: 0.7941\n",
      "Epoch 281/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1975 - accuracy: 0.9282 - val_loss: 1.1776 - val_accuracy: 0.7941\n",
      "Epoch 282/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1938 - accuracy: 0.9273 - val_loss: 1.1621 - val_accuracy: 0.7967\n",
      "Epoch 283/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1987 - accuracy: 0.9272 - val_loss: 1.1756 - val_accuracy: 0.7958\n",
      "Epoch 284/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1942 - accuracy: 0.9290 - val_loss: 1.1646 - val_accuracy: 0.7951\n",
      "Epoch 285/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1967 - accuracy: 0.9273 - val_loss: 1.1709 - val_accuracy: 0.7972\n",
      "Epoch 286/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1944 - accuracy: 0.9287 - val_loss: 1.1751 - val_accuracy: 0.7958\n",
      "Epoch 287/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1948 - accuracy: 0.9272 - val_loss: 1.1730 - val_accuracy: 0.7987\n",
      "Epoch 288/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1971 - accuracy: 0.9267 - val_loss: 1.1703 - val_accuracy: 0.7929\n",
      "Epoch 289/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1924 - accuracy: 0.9303 - val_loss: 1.1700 - val_accuracy: 0.7941\n",
      "Epoch 290/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1940 - accuracy: 0.9290 - val_loss: 1.1655 - val_accuracy: 0.7967\n",
      "Epoch 291/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1953 - accuracy: 0.9273 - val_loss: 1.1800 - val_accuracy: 0.7941\n",
      "Epoch 292/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1920 - accuracy: 0.9311 - val_loss: 1.1831 - val_accuracy: 0.7903\n",
      "Epoch 293/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1935 - accuracy: 0.9282 - val_loss: 1.1687 - val_accuracy: 0.8006\n",
      "Epoch 294/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1911 - accuracy: 0.9297 - val_loss: 1.1820 - val_accuracy: 0.7946\n",
      "Epoch 295/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1933 - accuracy: 0.9295 - val_loss: 1.1978 - val_accuracy: 0.7910\n",
      "Epoch 296/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1953 - accuracy: 0.9287 - val_loss: 1.1905 - val_accuracy: 0.7934\n",
      "Epoch 297/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1935 - accuracy: 0.9287 - val_loss: 1.1698 - val_accuracy: 0.7989\n",
      "Epoch 298/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1935 - accuracy: 0.9292 - val_loss: 1.1829 - val_accuracy: 0.7984\n",
      "Epoch 299/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1911 - accuracy: 0.9300 - val_loss: 1.1705 - val_accuracy: 0.7963\n",
      "Epoch 300/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1927 - accuracy: 0.9288 - val_loss: 1.1739 - val_accuracy: 0.7955\n",
      "Epoch 301/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1914 - accuracy: 0.9294 - val_loss: 1.1884 - val_accuracy: 0.7893\n",
      "Epoch 302/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1934 - accuracy: 0.9282 - val_loss: 1.1928 - val_accuracy: 0.7941\n",
      "Epoch 303/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1936 - accuracy: 0.9297 - val_loss: 1.1909 - val_accuracy: 0.7915\n",
      "Epoch 304/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1891 - accuracy: 0.9306 - val_loss: 1.1809 - val_accuracy: 0.8006\n",
      "Epoch 305/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1890 - accuracy: 0.9325 - val_loss: 1.1841 - val_accuracy: 0.7934\n",
      "Epoch 306/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1904 - accuracy: 0.9310 - val_loss: 1.2006 - val_accuracy: 0.7922\n",
      "Epoch 307/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1916 - accuracy: 0.9304 - val_loss: 1.1979 - val_accuracy: 0.7943\n",
      "Epoch 308/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1902 - accuracy: 0.9305 - val_loss: 1.1993 - val_accuracy: 0.7958\n",
      "Epoch 309/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1896 - accuracy: 0.9323 - val_loss: 1.2013 - val_accuracy: 0.7939\n",
      "Epoch 310/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1923 - accuracy: 0.9287 - val_loss: 1.1967 - val_accuracy: 0.7955\n",
      "Epoch 311/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1899 - accuracy: 0.9317 - val_loss: 1.1969 - val_accuracy: 0.7987\n",
      "Epoch 312/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1888 - accuracy: 0.9311 - val_loss: 1.2019 - val_accuracy: 0.7970\n",
      "Epoch 313/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1889 - accuracy: 0.9302 - val_loss: 1.2160 - val_accuracy: 0.7879\n",
      "Epoch 314/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1891 - accuracy: 0.9307 - val_loss: 1.2141 - val_accuracy: 0.7922\n",
      "Epoch 315/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1902 - accuracy: 0.9299 - val_loss: 1.2071 - val_accuracy: 0.7939\n",
      "Epoch 316/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1891 - accuracy: 0.9306 - val_loss: 1.1957 - val_accuracy: 0.8008\n",
      "Epoch 317/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1893 - accuracy: 0.9309 - val_loss: 1.2132 - val_accuracy: 0.7915\n",
      "Epoch 318/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1867 - accuracy: 0.9308 - val_loss: 1.2070 - val_accuracy: 0.7996\n",
      "Epoch 319/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1878 - accuracy: 0.9315 - val_loss: 1.1989 - val_accuracy: 0.7905\n",
      "Epoch 320/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1895 - accuracy: 0.9319 - val_loss: 1.2026 - val_accuracy: 0.7970\n",
      "Epoch 321/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1871 - accuracy: 0.9317 - val_loss: 1.2097 - val_accuracy: 0.7951\n",
      "Epoch 322/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1870 - accuracy: 0.9316 - val_loss: 1.1979 - val_accuracy: 0.7979\n",
      "Epoch 323/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1866 - accuracy: 0.9323 - val_loss: 1.2152 - val_accuracy: 0.7989\n",
      "Epoch 324/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1858 - accuracy: 0.9321 - val_loss: 1.2057 - val_accuracy: 0.7996\n",
      "Epoch 325/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1874 - accuracy: 0.9309 - val_loss: 1.2085 - val_accuracy: 0.7994\n",
      "Epoch 326/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1874 - accuracy: 0.9327 - val_loss: 1.2072 - val_accuracy: 0.7948\n",
      "Epoch 327/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1877 - accuracy: 0.9318 - val_loss: 1.2184 - val_accuracy: 0.7987\n",
      "Epoch 328/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1875 - accuracy: 0.9321 - val_loss: 1.2107 - val_accuracy: 0.7951\n",
      "Epoch 329/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1851 - accuracy: 0.9321 - val_loss: 1.2126 - val_accuracy: 0.8003\n",
      "Epoch 330/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1893 - accuracy: 0.9312 - val_loss: 1.2272 - val_accuracy: 0.7970\n",
      "Epoch 331/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1853 - accuracy: 0.9321 - val_loss: 1.2126 - val_accuracy: 0.7958\n",
      "Epoch 332/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1859 - accuracy: 0.9319 - val_loss: 1.2212 - val_accuracy: 0.7972\n",
      "Epoch 333/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1854 - accuracy: 0.9312 - val_loss: 1.2241 - val_accuracy: 0.7948\n",
      "Epoch 334/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1878 - accuracy: 0.9311 - val_loss: 1.2309 - val_accuracy: 0.7876\n",
      "Epoch 335/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1847 - accuracy: 0.9335 - val_loss: 1.2284 - val_accuracy: 0.7910\n",
      "Epoch 336/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1862 - accuracy: 0.9315 - val_loss: 1.2229 - val_accuracy: 0.7965\n",
      "Epoch 337/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1843 - accuracy: 0.9311 - val_loss: 1.2212 - val_accuracy: 0.7953\n",
      "Epoch 338/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1835 - accuracy: 0.9330 - val_loss: 1.2257 - val_accuracy: 0.7963\n",
      "Epoch 339/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1831 - accuracy: 0.9342 - val_loss: 1.2258 - val_accuracy: 0.7939\n",
      "Epoch 340/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1854 - accuracy: 0.9311 - val_loss: 1.2224 - val_accuracy: 0.7970\n",
      "Epoch 341/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1848 - accuracy: 0.9327 - val_loss: 1.2413 - val_accuracy: 0.7893\n",
      "Epoch 342/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1846 - accuracy: 0.9316 - val_loss: 1.2423 - val_accuracy: 0.7958\n",
      "Epoch 343/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1852 - accuracy: 0.9316 - val_loss: 1.2338 - val_accuracy: 0.7917\n",
      "Epoch 344/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1833 - accuracy: 0.9347 - val_loss: 1.2341 - val_accuracy: 0.7955\n",
      "Epoch 345/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1828 - accuracy: 0.9357 - val_loss: 1.2326 - val_accuracy: 0.7934\n",
      "Epoch 346/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1820 - accuracy: 0.9318 - val_loss: 1.2331 - val_accuracy: 0.7958\n",
      "Epoch 347/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1825 - accuracy: 0.9343 - val_loss: 1.2334 - val_accuracy: 0.7991\n",
      "Epoch 348/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1831 - accuracy: 0.9322 - val_loss: 1.2470 - val_accuracy: 0.7941\n",
      "Epoch 349/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1882 - accuracy: 0.9326 - val_loss: 1.2350 - val_accuracy: 0.7953\n",
      "Epoch 350/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1818 - accuracy: 0.9336 - val_loss: 1.2507 - val_accuracy: 0.7871\n",
      "Epoch 351/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1794 - accuracy: 0.9342 - val_loss: 1.2278 - val_accuracy: 0.7943\n",
      "Epoch 352/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1818 - accuracy: 0.9340 - val_loss: 1.2350 - val_accuracy: 0.7989\n",
      "Epoch 353/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1837 - accuracy: 0.9324 - val_loss: 1.2378 - val_accuracy: 0.7953\n",
      "Epoch 354/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1794 - accuracy: 0.9361 - val_loss: 1.2417 - val_accuracy: 0.7953\n",
      "Epoch 355/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1826 - accuracy: 0.9326 - val_loss: 1.2545 - val_accuracy: 0.7963\n",
      "Epoch 356/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1817 - accuracy: 0.9339 - val_loss: 1.2500 - val_accuracy: 0.7953\n",
      "Epoch 357/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1819 - accuracy: 0.9331 - val_loss: 1.2406 - val_accuracy: 0.7958\n",
      "Epoch 358/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1834 - accuracy: 0.9329 - val_loss: 1.2457 - val_accuracy: 0.7987\n",
      "Epoch 359/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1799 - accuracy: 0.9320 - val_loss: 1.2582 - val_accuracy: 0.7975\n",
      "Epoch 360/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1803 - accuracy: 0.9338 - val_loss: 1.2664 - val_accuracy: 0.7953\n",
      "Epoch 361/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1788 - accuracy: 0.9347 - val_loss: 1.2602 - val_accuracy: 0.7963\n",
      "Epoch 362/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1822 - accuracy: 0.9318 - val_loss: 1.2515 - val_accuracy: 0.7948\n",
      "Epoch 363/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1785 - accuracy: 0.9363 - val_loss: 1.2580 - val_accuracy: 0.7996\n",
      "Epoch 364/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1806 - accuracy: 0.9347 - val_loss: 1.2723 - val_accuracy: 0.7965\n",
      "Epoch 365/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1795 - accuracy: 0.9344 - val_loss: 1.2554 - val_accuracy: 0.7934\n",
      "Epoch 366/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1785 - accuracy: 0.9362 - val_loss: 1.2542 - val_accuracy: 0.7977\n",
      "Epoch 367/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1817 - accuracy: 0.9325 - val_loss: 1.2504 - val_accuracy: 0.7955\n",
      "Epoch 368/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1781 - accuracy: 0.9356 - val_loss: 1.2653 - val_accuracy: 0.7996\n",
      "Epoch 369/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1779 - accuracy: 0.9342 - val_loss: 1.2578 - val_accuracy: 0.8001\n",
      "Epoch 370/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1798 - accuracy: 0.9353 - val_loss: 1.2689 - val_accuracy: 0.7999\n",
      "Epoch 371/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1779 - accuracy: 0.9354 - val_loss: 1.2659 - val_accuracy: 0.7965\n",
      "Epoch 372/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1784 - accuracy: 0.9361 - val_loss: 1.2615 - val_accuracy: 0.7984\n",
      "Epoch 373/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1764 - accuracy: 0.9375 - val_loss: 1.2557 - val_accuracy: 0.7977\n",
      "Epoch 374/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1771 - accuracy: 0.9364 - val_loss: 1.2682 - val_accuracy: 0.7891\n",
      "Epoch 375/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1812 - accuracy: 0.9312 - val_loss: 1.2675 - val_accuracy: 0.7953\n",
      "Epoch 376/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1804 - accuracy: 0.9339 - val_loss: 1.2684 - val_accuracy: 0.7982\n",
      "Epoch 377/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1771 - accuracy: 0.9356 - val_loss: 1.2680 - val_accuracy: 0.7991\n",
      "Epoch 378/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1760 - accuracy: 0.9360 - val_loss: 1.2745 - val_accuracy: 0.7960\n",
      "Epoch 379/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1754 - accuracy: 0.9363 - val_loss: 1.2960 - val_accuracy: 0.7847\n",
      "Epoch 380/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1786 - accuracy: 0.9352 - val_loss: 1.2741 - val_accuracy: 0.7919\n",
      "Epoch 381/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1775 - accuracy: 0.9357 - val_loss: 1.2661 - val_accuracy: 0.7963\n",
      "Epoch 382/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1777 - accuracy: 0.9372 - val_loss: 1.2827 - val_accuracy: 0.7919\n",
      "Epoch 383/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1760 - accuracy: 0.9357 - val_loss: 1.2928 - val_accuracy: 0.7874\n",
      "Epoch 384/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1787 - accuracy: 0.9347 - val_loss: 1.2702 - val_accuracy: 0.7979\n",
      "Epoch 385/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1758 - accuracy: 0.9353 - val_loss: 1.2681 - val_accuracy: 0.7941\n",
      "Epoch 386/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1753 - accuracy: 0.9372 - val_loss: 1.2845 - val_accuracy: 0.7943\n",
      "Epoch 387/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1789 - accuracy: 0.9348 - val_loss: 1.2707 - val_accuracy: 0.7955\n",
      "Epoch 388/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1741 - accuracy: 0.9366 - val_loss: 1.2829 - val_accuracy: 0.7989\n",
      "Epoch 389/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1769 - accuracy: 0.9346 - val_loss: 1.2949 - val_accuracy: 0.7982\n",
      "Epoch 390/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1763 - accuracy: 0.9352 - val_loss: 1.2826 - val_accuracy: 0.7987\n",
      "Epoch 391/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1765 - accuracy: 0.9354 - val_loss: 1.2716 - val_accuracy: 0.7987\n",
      "Epoch 392/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1734 - accuracy: 0.9350 - val_loss: 1.2839 - val_accuracy: 0.7960\n",
      "Epoch 393/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1741 - accuracy: 0.9352 - val_loss: 1.2895 - val_accuracy: 0.7917\n",
      "Epoch 394/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1761 - accuracy: 0.9362 - val_loss: 1.2895 - val_accuracy: 0.7919\n",
      "Epoch 395/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1774 - accuracy: 0.9343 - val_loss: 1.2768 - val_accuracy: 0.7970\n",
      "Epoch 396/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1741 - accuracy: 0.9360 - val_loss: 1.2742 - val_accuracy: 0.7941\n",
      "Epoch 397/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1752 - accuracy: 0.9353 - val_loss: 1.2923 - val_accuracy: 0.7943\n",
      "Epoch 398/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1722 - accuracy: 0.9388 - val_loss: 1.3077 - val_accuracy: 0.7951\n",
      "Epoch 399/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1766 - accuracy: 0.9352 - val_loss: 1.2953 - val_accuracy: 0.7965\n",
      "Epoch 400/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1721 - accuracy: 0.9373 - val_loss: 1.2930 - val_accuracy: 0.7934\n",
      "Epoch 401/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1722 - accuracy: 0.9368 - val_loss: 1.2857 - val_accuracy: 0.8001\n",
      "Epoch 402/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1732 - accuracy: 0.9366 - val_loss: 1.2894 - val_accuracy: 0.7987\n",
      "Epoch 403/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1733 - accuracy: 0.9364 - val_loss: 1.2986 - val_accuracy: 0.7972\n",
      "Epoch 404/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1718 - accuracy: 0.9356 - val_loss: 1.2905 - val_accuracy: 0.7951\n",
      "Epoch 405/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1739 - accuracy: 0.9369 - val_loss: 1.2983 - val_accuracy: 0.7979\n",
      "Epoch 406/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1718 - accuracy: 0.9383 - val_loss: 1.3064 - val_accuracy: 0.7991\n",
      "Epoch 407/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1734 - accuracy: 0.9365 - val_loss: 1.3113 - val_accuracy: 0.7953\n",
      "Epoch 408/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1728 - accuracy: 0.9375 - val_loss: 1.3052 - val_accuracy: 0.7939\n",
      "Epoch 409/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1718 - accuracy: 0.9381 - val_loss: 1.2983 - val_accuracy: 0.7960\n",
      "Epoch 410/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1718 - accuracy: 0.9363 - val_loss: 1.3065 - val_accuracy: 0.7960\n",
      "Epoch 411/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1733 - accuracy: 0.9351 - val_loss: 1.3095 - val_accuracy: 0.7958\n",
      "Epoch 412/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1726 - accuracy: 0.9359 - val_loss: 1.3117 - val_accuracy: 0.7924\n",
      "Epoch 413/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1717 - accuracy: 0.9383 - val_loss: 1.3143 - val_accuracy: 0.7907\n",
      "Epoch 414/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1713 - accuracy: 0.9371 - val_loss: 1.3049 - val_accuracy: 0.7931\n",
      "Epoch 415/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1711 - accuracy: 0.9391 - val_loss: 1.3217 - val_accuracy: 0.7955\n",
      "Epoch 416/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1709 - accuracy: 0.9387 - val_loss: 1.3110 - val_accuracy: 0.7953\n",
      "Epoch 417/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1706 - accuracy: 0.9386 - val_loss: 1.3137 - val_accuracy: 0.7960\n",
      "Epoch 418/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1712 - accuracy: 0.9366 - val_loss: 1.3229 - val_accuracy: 0.7994\n",
      "Epoch 419/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1708 - accuracy: 0.9377 - val_loss: 1.3156 - val_accuracy: 0.7936\n",
      "Epoch 420/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1684 - accuracy: 0.9393 - val_loss: 1.3077 - val_accuracy: 0.7987\n",
      "Epoch 421/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1706 - accuracy: 0.9379 - val_loss: 1.3138 - val_accuracy: 0.7977\n",
      "Epoch 422/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1700 - accuracy: 0.9380 - val_loss: 1.3085 - val_accuracy: 0.8008\n",
      "Epoch 423/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1698 - accuracy: 0.9382 - val_loss: 1.3296 - val_accuracy: 0.7946\n",
      "Epoch 424/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1725 - accuracy: 0.9372 - val_loss: 1.3242 - val_accuracy: 0.7948\n",
      "Epoch 425/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1718 - accuracy: 0.9375 - val_loss: 1.3292 - val_accuracy: 0.7893\n",
      "Epoch 426/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1705 - accuracy: 0.9377 - val_loss: 1.3278 - val_accuracy: 0.7970\n",
      "Epoch 427/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1676 - accuracy: 0.9404 - val_loss: 1.3298 - val_accuracy: 0.7936\n",
      "Epoch 428/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1708 - accuracy: 0.9372 - val_loss: 1.3210 - val_accuracy: 0.7955\n",
      "Epoch 429/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1682 - accuracy: 0.9389 - val_loss: 1.3367 - val_accuracy: 0.7934\n",
      "Epoch 430/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1692 - accuracy: 0.9394 - val_loss: 1.3184 - val_accuracy: 0.7941\n",
      "Epoch 431/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1707 - accuracy: 0.9371 - val_loss: 1.3337 - val_accuracy: 0.7879\n",
      "Epoch 432/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1708 - accuracy: 0.9371 - val_loss: 1.3151 - val_accuracy: 0.7982\n",
      "Epoch 433/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1671 - accuracy: 0.9397 - val_loss: 1.3322 - val_accuracy: 0.7951\n",
      "Epoch 434/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1656 - accuracy: 0.9393 - val_loss: 1.3321 - val_accuracy: 0.7951\n",
      "Epoch 435/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1684 - accuracy: 0.9390 - val_loss: 1.3337 - val_accuracy: 0.7970\n",
      "Epoch 436/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1666 - accuracy: 0.9389 - val_loss: 1.3404 - val_accuracy: 0.7946\n",
      "Epoch 437/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1686 - accuracy: 0.9384 - val_loss: 1.3301 - val_accuracy: 0.7967\n",
      "Epoch 438/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1701 - accuracy: 0.9390 - val_loss: 1.3387 - val_accuracy: 0.7970\n",
      "Epoch 439/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1661 - accuracy: 0.9396 - val_loss: 1.3354 - val_accuracy: 0.7948\n",
      "Epoch 440/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1689 - accuracy: 0.9378 - val_loss: 1.3361 - val_accuracy: 0.7987\n",
      "Epoch 441/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1659 - accuracy: 0.9391 - val_loss: 1.3472 - val_accuracy: 0.7977\n",
      "Epoch 442/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1643 - accuracy: 0.9411 - val_loss: 1.3397 - val_accuracy: 0.7943\n",
      "Epoch 443/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1663 - accuracy: 0.9392 - val_loss: 1.3500 - val_accuracy: 0.7895\n",
      "Epoch 444/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1656 - accuracy: 0.9405 - val_loss: 1.3468 - val_accuracy: 0.7994\n",
      "Epoch 445/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1643 - accuracy: 0.9408 - val_loss: 1.3348 - val_accuracy: 0.7915\n",
      "Epoch 446/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1653 - accuracy: 0.9400 - val_loss: 1.3572 - val_accuracy: 0.7946\n",
      "Epoch 447/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1677 - accuracy: 0.9383 - val_loss: 1.3449 - val_accuracy: 0.7941\n",
      "Epoch 448/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1678 - accuracy: 0.9373 - val_loss: 1.3370 - val_accuracy: 0.7963\n",
      "Epoch 449/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1639 - accuracy: 0.9424 - val_loss: 1.3552 - val_accuracy: 0.7977\n",
      "Epoch 450/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1655 - accuracy: 0.9394 - val_loss: 1.3417 - val_accuracy: 0.7987\n",
      "Epoch 451/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1641 - accuracy: 0.9416 - val_loss: 1.3755 - val_accuracy: 0.7881\n",
      "Epoch 452/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1654 - accuracy: 0.9402 - val_loss: 1.3633 - val_accuracy: 0.7927\n",
      "Epoch 453/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1651 - accuracy: 0.9412 - val_loss: 1.3751 - val_accuracy: 0.7936\n",
      "Epoch 454/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1665 - accuracy: 0.9404 - val_loss: 1.3694 - val_accuracy: 0.7972\n",
      "Epoch 455/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1632 - accuracy: 0.9415 - val_loss: 1.3660 - val_accuracy: 0.7929\n",
      "Epoch 456/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1640 - accuracy: 0.9396 - val_loss: 1.3714 - val_accuracy: 0.7948\n",
      "Epoch 457/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1640 - accuracy: 0.9404 - val_loss: 1.3677 - val_accuracy: 0.7931\n",
      "Epoch 458/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1644 - accuracy: 0.9400 - val_loss: 1.3591 - val_accuracy: 0.7953\n",
      "Epoch 459/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1624 - accuracy: 0.9402 - val_loss: 1.3565 - val_accuracy: 0.8008\n",
      "Epoch 460/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1645 - accuracy: 0.9401 - val_loss: 1.3662 - val_accuracy: 0.7963\n",
      "Epoch 461/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1666 - accuracy: 0.9398 - val_loss: 1.3671 - val_accuracy: 0.7977\n",
      "Epoch 462/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1660 - accuracy: 0.9429 - val_loss: 1.3657 - val_accuracy: 0.7895\n",
      "Epoch 463/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1639 - accuracy: 0.9402 - val_loss: 1.3543 - val_accuracy: 0.7982\n",
      "Epoch 464/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1616 - accuracy: 0.9420 - val_loss: 1.3675 - val_accuracy: 0.7941\n",
      "Epoch 465/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1644 - accuracy: 0.9405 - val_loss: 1.3700 - val_accuracy: 0.7929\n",
      "Epoch 466/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1633 - accuracy: 0.9420 - val_loss: 1.3724 - val_accuracy: 0.7931\n",
      "Epoch 467/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1619 - accuracy: 0.9412 - val_loss: 1.3697 - val_accuracy: 0.7929\n",
      "Epoch 468/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1615 - accuracy: 0.9405 - val_loss: 1.3616 - val_accuracy: 0.7891\n",
      "Epoch 469/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1627 - accuracy: 0.9404 - val_loss: 1.3693 - val_accuracy: 0.7955\n",
      "Epoch 470/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1602 - accuracy: 0.9414 - val_loss: 1.3790 - val_accuracy: 0.7917\n",
      "Epoch 471/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1664 - accuracy: 0.9387 - val_loss: 1.3711 - val_accuracy: 0.7975\n",
      "Epoch 472/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1623 - accuracy: 0.9419 - val_loss: 1.3743 - val_accuracy: 0.7907\n",
      "Epoch 473/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1624 - accuracy: 0.9422 - val_loss: 1.3898 - val_accuracy: 0.7989\n",
      "Epoch 474/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1633 - accuracy: 0.9398 - val_loss: 1.3674 - val_accuracy: 0.7953\n",
      "Epoch 475/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1604 - accuracy: 0.9426 - val_loss: 1.3682 - val_accuracy: 0.8008\n",
      "Epoch 476/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1657 - accuracy: 0.9403 - val_loss: 1.3756 - val_accuracy: 0.7927\n",
      "Epoch 477/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1620 - accuracy: 0.9423 - val_loss: 1.3990 - val_accuracy: 0.7912\n",
      "Epoch 478/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1615 - accuracy: 0.9408 - val_loss: 1.4025 - val_accuracy: 0.7857\n",
      "Epoch 479/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1620 - accuracy: 0.9413 - val_loss: 1.3834 - val_accuracy: 0.7936\n",
      "Epoch 480/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1628 - accuracy: 0.9411 - val_loss: 1.3730 - val_accuracy: 0.7946\n",
      "Epoch 481/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1583 - accuracy: 0.9426 - val_loss: 1.3874 - val_accuracy: 0.7917\n",
      "Epoch 482/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1590 - accuracy: 0.9438 - val_loss: 1.4006 - val_accuracy: 0.7910\n",
      "Epoch 483/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1606 - accuracy: 0.9410 - val_loss: 1.3931 - val_accuracy: 0.7963\n",
      "Epoch 484/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1590 - accuracy: 0.9417 - val_loss: 1.3943 - val_accuracy: 0.7955\n",
      "Epoch 485/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1604 - accuracy: 0.9423 - val_loss: 1.3939 - val_accuracy: 0.7958\n",
      "Epoch 486/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1589 - accuracy: 0.9417 - val_loss: 1.3760 - val_accuracy: 0.7943\n",
      "Epoch 487/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1568 - accuracy: 0.9437 - val_loss: 1.4106 - val_accuracy: 0.7919\n",
      "Epoch 488/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1611 - accuracy: 0.9410 - val_loss: 1.3934 - val_accuracy: 0.7960\n",
      "Epoch 489/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1585 - accuracy: 0.9425 - val_loss: 1.3986 - val_accuracy: 0.7922\n",
      "Epoch 490/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1629 - accuracy: 0.9405 - val_loss: 1.3932 - val_accuracy: 0.7927\n",
      "Epoch 491/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1600 - accuracy: 0.9430 - val_loss: 1.3931 - val_accuracy: 0.7958\n",
      "Epoch 492/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1601 - accuracy: 0.9409 - val_loss: 1.3959 - val_accuracy: 0.7984\n",
      "Epoch 493/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1605 - accuracy: 0.9413 - val_loss: 1.3780 - val_accuracy: 0.7951\n",
      "Epoch 494/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1616 - accuracy: 0.9419 - val_loss: 1.4359 - val_accuracy: 0.7879\n",
      "Epoch 495/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1587 - accuracy: 0.9432 - val_loss: 1.4050 - val_accuracy: 0.7982\n",
      "Epoch 496/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1578 - accuracy: 0.9442 - val_loss: 1.4034 - val_accuracy: 0.7972\n",
      "Epoch 497/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1587 - accuracy: 0.9428 - val_loss: 1.4126 - val_accuracy: 0.7910\n",
      "Epoch 498/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1573 - accuracy: 0.9442 - val_loss: 1.4098 - val_accuracy: 0.7960\n",
      "Epoch 499/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1571 - accuracy: 0.9438 - val_loss: 1.4052 - val_accuracy: 0.7927\n",
      "Epoch 500/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1578 - accuracy: 0.9425 - val_loss: 1.4058 - val_accuracy: 0.7989\n",
      "Epoch 501/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1565 - accuracy: 0.9441 - val_loss: 1.4158 - val_accuracy: 0.7948\n",
      "Epoch 502/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1569 - accuracy: 0.9430 - val_loss: 1.4145 - val_accuracy: 0.7924\n",
      "Epoch 503/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1556 - accuracy: 0.9444 - val_loss: 1.4277 - val_accuracy: 0.7915\n",
      "Epoch 504/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1553 - accuracy: 0.9425 - val_loss: 1.4107 - val_accuracy: 0.7979\n",
      "Epoch 505/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1567 - accuracy: 0.9427 - val_loss: 1.4220 - val_accuracy: 0.7910\n",
      "Epoch 506/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1590 - accuracy: 0.9425 - val_loss: 1.4457 - val_accuracy: 0.7934\n",
      "Epoch 507/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1564 - accuracy: 0.9431 - val_loss: 1.4360 - val_accuracy: 0.7953\n",
      "Epoch 508/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1539 - accuracy: 0.9445 - val_loss: 1.4204 - val_accuracy: 0.7975\n",
      "Epoch 509/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1554 - accuracy: 0.9438 - val_loss: 1.4410 - val_accuracy: 0.7953\n",
      "Epoch 510/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1556 - accuracy: 0.9444 - val_loss: 1.4241 - val_accuracy: 0.7951\n",
      "Epoch 511/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1572 - accuracy: 0.9432 - val_loss: 1.4269 - val_accuracy: 0.7977\n",
      "Epoch 512/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1572 - accuracy: 0.9428 - val_loss: 1.4259 - val_accuracy: 0.7965\n",
      "Epoch 513/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1557 - accuracy: 0.9443 - val_loss: 1.4141 - val_accuracy: 0.7946\n",
      "Epoch 514/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1579 - accuracy: 0.9421 - val_loss: 1.4277 - val_accuracy: 0.7984\n",
      "Epoch 515/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1558 - accuracy: 0.9433 - val_loss: 1.4259 - val_accuracy: 0.7977\n",
      "Epoch 516/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1550 - accuracy: 0.9447 - val_loss: 1.4364 - val_accuracy: 0.8015\n",
      "Epoch 517/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1573 - accuracy: 0.9420 - val_loss: 1.4339 - val_accuracy: 0.7905\n",
      "Epoch 518/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1547 - accuracy: 0.9449 - val_loss: 1.4267 - val_accuracy: 0.7975\n",
      "Epoch 519/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1533 - accuracy: 0.9447 - val_loss: 1.4419 - val_accuracy: 0.7912\n",
      "Epoch 520/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1565 - accuracy: 0.9424 - val_loss: 1.4377 - val_accuracy: 0.7943\n",
      "Epoch 521/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1553 - accuracy: 0.9436 - val_loss: 1.4387 - val_accuracy: 0.8008\n",
      "Epoch 522/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1552 - accuracy: 0.9435 - val_loss: 1.4444 - val_accuracy: 0.7946\n",
      "Epoch 523/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1544 - accuracy: 0.9427 - val_loss: 1.4255 - val_accuracy: 0.7939\n",
      "Epoch 524/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1570 - accuracy: 0.9432 - val_loss: 1.4478 - val_accuracy: 0.7924\n",
      "Epoch 525/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1561 - accuracy: 0.9431 - val_loss: 1.4572 - val_accuracy: 0.7936\n",
      "Epoch 526/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1537 - accuracy: 0.9446 - val_loss: 1.4385 - val_accuracy: 0.7960\n",
      "Epoch 527/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1523 - accuracy: 0.9448 - val_loss: 1.4398 - val_accuracy: 0.7936\n",
      "Epoch 528/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1542 - accuracy: 0.9452 - val_loss: 1.4438 - val_accuracy: 0.7915\n",
      "Epoch 529/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1511 - accuracy: 0.9461 - val_loss: 1.4497 - val_accuracy: 0.7967\n",
      "Epoch 530/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1547 - accuracy: 0.9446 - val_loss: 1.4382 - val_accuracy: 0.7941\n",
      "Epoch 531/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1536 - accuracy: 0.9438 - val_loss: 1.4545 - val_accuracy: 0.7934\n",
      "Epoch 532/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1514 - accuracy: 0.9457 - val_loss: 1.4561 - val_accuracy: 0.7948\n",
      "Epoch 533/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1521 - accuracy: 0.9455 - val_loss: 1.4641 - val_accuracy: 0.7960\n",
      "Epoch 534/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1528 - accuracy: 0.9452 - val_loss: 1.4474 - val_accuracy: 0.7989\n",
      "Epoch 535/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1529 - accuracy: 0.9439 - val_loss: 1.4622 - val_accuracy: 0.7931\n",
      "Epoch 536/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1518 - accuracy: 0.9462 - val_loss: 1.4581 - val_accuracy: 0.7936\n",
      "Epoch 537/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1521 - accuracy: 0.9447 - val_loss: 1.4458 - val_accuracy: 0.7965\n",
      "Epoch 538/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1512 - accuracy: 0.9463 - val_loss: 1.4598 - val_accuracy: 0.7982\n",
      "Epoch 539/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1562 - accuracy: 0.9434 - val_loss: 1.4635 - val_accuracy: 0.7970\n",
      "Epoch 540/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1507 - accuracy: 0.9460 - val_loss: 1.4543 - val_accuracy: 0.7931\n",
      "Epoch 541/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1506 - accuracy: 0.9469 - val_loss: 1.4570 - val_accuracy: 0.7936\n",
      "Epoch 542/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1549 - accuracy: 0.9446 - val_loss: 1.4537 - val_accuracy: 0.7946\n",
      "Epoch 543/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1520 - accuracy: 0.9459 - val_loss: 1.4577 - val_accuracy: 0.7943\n",
      "Epoch 544/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1501 - accuracy: 0.9471 - val_loss: 1.4517 - val_accuracy: 0.7951\n",
      "Epoch 545/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1508 - accuracy: 0.9452 - val_loss: 1.4552 - val_accuracy: 0.7972\n",
      "Epoch 546/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1533 - accuracy: 0.9442 - val_loss: 1.4726 - val_accuracy: 0.7989\n",
      "Epoch 547/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1505 - accuracy: 0.9459 - val_loss: 1.4727 - val_accuracy: 0.7972\n",
      "Epoch 548/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1538 - accuracy: 0.9452 - val_loss: 1.4691 - val_accuracy: 0.7931\n",
      "Epoch 549/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1510 - accuracy: 0.9467 - val_loss: 1.4641 - val_accuracy: 0.8003\n",
      "Epoch 550/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1492 - accuracy: 0.9460 - val_loss: 1.4775 - val_accuracy: 0.7948\n",
      "Epoch 551/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1488 - accuracy: 0.9477 - val_loss: 1.4754 - val_accuracy: 0.7960\n",
      "Epoch 552/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1491 - accuracy: 0.9459 - val_loss: 1.4785 - val_accuracy: 0.7965\n",
      "Epoch 553/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1479 - accuracy: 0.9458 - val_loss: 1.4714 - val_accuracy: 0.7939\n",
      "Epoch 554/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1529 - accuracy: 0.9444 - val_loss: 1.4729 - val_accuracy: 0.7972\n",
      "Epoch 555/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1516 - accuracy: 0.9451 - val_loss: 1.4693 - val_accuracy: 0.7955\n",
      "Epoch 556/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1507 - accuracy: 0.9461 - val_loss: 1.4857 - val_accuracy: 0.7924\n",
      "Epoch 557/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1496 - accuracy: 0.9465 - val_loss: 1.4984 - val_accuracy: 0.7936\n",
      "Epoch 558/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1494 - accuracy: 0.9463 - val_loss: 1.4867 - val_accuracy: 0.7953\n",
      "Epoch 559/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1489 - accuracy: 0.9468 - val_loss: 1.4803 - val_accuracy: 0.7970\n",
      "Epoch 560/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1450 - accuracy: 0.9492 - val_loss: 1.4815 - val_accuracy: 0.7917\n",
      "Epoch 561/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1469 - accuracy: 0.9479 - val_loss: 1.4742 - val_accuracy: 0.7951\n",
      "Epoch 562/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1498 - accuracy: 0.9461 - val_loss: 1.4726 - val_accuracy: 0.7972\n",
      "Epoch 563/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1479 - accuracy: 0.9482 - val_loss: 1.4855 - val_accuracy: 0.7924\n",
      "Epoch 564/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1478 - accuracy: 0.9471 - val_loss: 1.4825 - val_accuracy: 0.7975\n",
      "Epoch 565/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1492 - accuracy: 0.9473 - val_loss: 1.5009 - val_accuracy: 0.7970\n",
      "Epoch 566/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1520 - accuracy: 0.9453 - val_loss: 1.5110 - val_accuracy: 0.7900\n",
      "Epoch 567/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1505 - accuracy: 0.9452 - val_loss: 1.4975 - val_accuracy: 0.7898\n",
      "Epoch 568/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1471 - accuracy: 0.9476 - val_loss: 1.4901 - val_accuracy: 0.7919\n",
      "Epoch 569/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1492 - accuracy: 0.9462 - val_loss: 1.4889 - val_accuracy: 0.7951\n",
      "Epoch 570/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1474 - accuracy: 0.9471 - val_loss: 1.4872 - val_accuracy: 0.7960\n",
      "Epoch 571/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1457 - accuracy: 0.9469 - val_loss: 1.4907 - val_accuracy: 0.7977\n",
      "Epoch 572/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1449 - accuracy: 0.9496 - val_loss: 1.4925 - val_accuracy: 0.7931\n",
      "Epoch 573/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1490 - accuracy: 0.9458 - val_loss: 1.5140 - val_accuracy: 0.7912\n",
      "Epoch 574/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1504 - accuracy: 0.9458 - val_loss: 1.4955 - val_accuracy: 0.7963\n",
      "Epoch 575/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1472 - accuracy: 0.9449 - val_loss: 1.4868 - val_accuracy: 0.7941\n",
      "Epoch 576/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1477 - accuracy: 0.9464 - val_loss: 1.5091 - val_accuracy: 0.7970\n",
      "Epoch 577/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1465 - accuracy: 0.9466 - val_loss: 1.4911 - val_accuracy: 0.7965\n",
      "Epoch 578/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1480 - accuracy: 0.9459 - val_loss: 1.5132 - val_accuracy: 0.7936\n",
      "Epoch 579/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1486 - accuracy: 0.9464 - val_loss: 1.5009 - val_accuracy: 0.7948\n",
      "Epoch 580/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1457 - accuracy: 0.9477 - val_loss: 1.5020 - val_accuracy: 0.7963\n",
      "Epoch 581/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1471 - accuracy: 0.9465 - val_loss: 1.5012 - val_accuracy: 0.7912\n",
      "Epoch 582/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1445 - accuracy: 0.9489 - val_loss: 1.5092 - val_accuracy: 0.7972\n",
      "Epoch 583/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1450 - accuracy: 0.9465 - val_loss: 1.5268 - val_accuracy: 0.7936\n",
      "Epoch 584/600\n",
      "261/261 [==============================] - 65s 249ms/step - loss: 0.1464 - accuracy: 0.9476 - val_loss: 1.5075 - val_accuracy: 0.7943\n",
      "Epoch 585/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1459 - accuracy: 0.9472 - val_loss: 1.5189 - val_accuracy: 0.7975\n",
      "Epoch 586/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1415 - accuracy: 0.9492 - val_loss: 1.5197 - val_accuracy: 0.7958\n",
      "Epoch 587/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1464 - accuracy: 0.9469 - val_loss: 1.5104 - val_accuracy: 0.7946\n",
      "Epoch 588/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1494 - accuracy: 0.9448 - val_loss: 1.5005 - val_accuracy: 0.7912\n",
      "Epoch 589/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1443 - accuracy: 0.9495 - val_loss: 1.5073 - val_accuracy: 0.7953\n",
      "Epoch 590/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1452 - accuracy: 0.9474 - val_loss: 1.5102 - val_accuracy: 0.8001\n",
      "Epoch 591/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1465 - accuracy: 0.9471 - val_loss: 1.5258 - val_accuracy: 0.8001\n",
      "Epoch 592/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1445 - accuracy: 0.9479 - val_loss: 1.5196 - val_accuracy: 0.7924\n",
      "Epoch 593/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1452 - accuracy: 0.9485 - val_loss: 1.5453 - val_accuracy: 0.7888\n",
      "Epoch 594/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1438 - accuracy: 0.9492 - val_loss: 1.5109 - val_accuracy: 0.7960\n",
      "Epoch 595/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1448 - accuracy: 0.9474 - val_loss: 1.5144 - val_accuracy: 0.7907\n",
      "Epoch 596/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1440 - accuracy: 0.9474 - val_loss: 1.5324 - val_accuracy: 0.7946\n",
      "Epoch 597/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1419 - accuracy: 0.9490 - val_loss: 1.5196 - val_accuracy: 0.7982\n",
      "Epoch 598/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1477 - accuracy: 0.9475 - val_loss: 1.5235 - val_accuracy: 0.7951\n",
      "Epoch 599/600\n",
      "261/261 [==============================] - 4s 15ms/step - loss: 0.1439 - accuracy: 0.9476 - val_loss: 1.5439 - val_accuracy: 0.7912\n",
      "Epoch 600/600\n",
      "261/261 [==============================] - 4s 14ms/step - loss: 0.1464 - accuracy: 0.9470 - val_loss: 1.5304 - val_accuracy: 0.7967\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compilamos el modelo con adam\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.00001)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "#entrenamos el modelo y validamos con X_test y y_test y bat size de 32\n",
    "history = model.fit(X_train_tensor, y_train_tensor, epochs = 600, validation_data = (X_test_tensor, y_test_tensor), batch_size = 64)\n",
    "\n",
    "#graficamos la matriz de confusion\n",
    "y_pred = model.predict(X_test_tensor)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "#guardamos el modelo\n",
    "model.save('modelos/modelo_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacemos las predicciones para el test\n",
    "X_test_final_tensor = tf.convert_to_tensor(test_drop.values, dtype=tf.float32)\n",
    "X_test_final_tensor = tf.keras.utils.normalize(X_test_final_tensor, axis=1)\n",
    "\n",
    "y_pred_final = model.predict(X_test_final_tensor)\n",
    "y_pred_final = np.argmax(y_pred_final, axis=1)\n",
    "\n",
    "#guardamos las predicciones\n",
    "dic_pred = {str(i) : y_pred_final[i] for i in range(len(y_pred_final))}\n",
    "dic_pred = {'target': dic_pred}\n",
    "df_pred = pd.DataFrame(dic_pred)\n",
    "df_pred.to_json('data/prediction.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.377 total time=  27.5s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.378 total time=  27.4s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.377 total time=  27.3s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.378 total time=  27.5s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.378 total time=  27.3s\n"
     ]
    }
   ],
   "source": [
    "#creamos una maquina de soporte vectorial con grid search \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#definimos los parametros\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "                'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "                }\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "\n",
    "#entrenamos\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#hacemos predicciones\n",
    "y_pred = grid.predict(X_test)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
